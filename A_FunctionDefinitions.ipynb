{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Overview of Functions\n",
    "\n",
    "To access all, `%run A_FunctionDefinitions.ipynb ;` \n",
    "\n",
    "### [Pre-Requesite Functions](#Setting-Pre-requisite-Functions-/-Importing-Libraries)\n",
    "`data=loadflow(gauge)` Returns dataframe directly loading the CAMELS provided streamflow data\n",
    "\n",
    "`fdc=FDC(gauge)` Returns dataframe with FDC info - Flow, Count Exceeded, Percent Exceeded\n",
    "\n",
    "### [FDC Plotting](#FDC-Plots)\n",
    "`fig=FDC_breakpoints(gauge)` Finds optimal breakpoint for 2 line representation of FDC, plots it\n",
    "\n",
    "`fig=MedianFDC(gauge)` Returns plot of each year's FDC, median annual FDC, and regular FDC\n",
    "\n",
    "`fig=MedianScaledFDC(gauge)` Returns plot of each year's FDC scaled to annual means, median of that, and regular FDC\n",
    "\n",
    "`fig=PeriodHydrographFDC(gauge)` Plots period of record FDC overlayed on Period Hydrograph\n",
    "\n",
    "`fig=HydrographFDCOverlay(gauge)` Overlays FDC and annual min/med/max hydrograph\n",
    "\n",
    "### [Other Streamflow Plotting](#Other-Streamflow-Plots)\n",
    "`fig=RasterHydrograph(gauge)` Return image of raster hydrograph, with no data in black\n",
    "\n",
    "`fig=StackedHydrograph(gauge)` Returns plot of each year's hydrograph year with min/med/max values for each day\n",
    "\n",
    "`fig=TypicalYear(gauge)` Returns plot of typical year with min/med/max values for each day\n",
    "\n",
    "`multiplot(gauge)` MapMaker, TypicalYear, RasterHydrograph, PeriodHydrographFDC\n",
    "\n",
    "### [Mapping](#I'M-THE-MAP!)\n",
    "`CONUSplot()` Creates plain map of the continental US\n",
    "\n",
    "`fig=MapMaker(gauge)` Returns map of CONUS with red dot at gauge location\n",
    "\n",
    "`mapdata(category,column,colorscale='divergent',gauge=[],subset=[],show=1)`\n",
    "\n",
    "### [Emphasize Selected Years](#Plots-to-Emphasize-Selected-Years)\n",
    "Note: `selected_years` should be bracketed list, even if only one year (ex: `=[1985]`)\n",
    "\n",
    "`fig=MedianFDC_selectyears(gauge,selected_years)` Returns plot specific year FDCs over all FDCs, median FDC, and regular FDC \n",
    "\n",
    "`fig=MedianScaledFDC_selectyears(gauge,selected_years)` Returns plot specific year scaled FDCs over all scaled FDCs, median FDC, and regular FDC \n",
    "\n",
    "`fig=TypicalYear_selectyears(gauge,selected_years)` Returns hydrograph of chosen years over period of record min/med/max \n",
    "\n",
    "### [Return Attribute Data](#Returning-Attribute-Data)\n",
    "`returnattributes(gauge)` Displays all CAMELS provided attributes, along with two sets of calculated streamflow figures\n",
    "\n",
    "`data=returnattributeset(dataset)`  Returns full dataframe of attributes/signatures \n",
    "\n",
    "### [Comparison Plots](#Some-Comparison-Plots)\n",
    "`fig=comparisonplot(dataX,columnX,dataY,columnY,dataZ='clim',columnZ='p_seasonality',gauge=[],colors=0,acceptable=[])` Plot of all gauges on x/y field, with color scale and gauge emphasis options\n",
    "\n",
    "`fig=subsetID(dataX,columnX,xrange,dataY,columnY,yrange,dataZ='clim',columnZ='p_seasonality',zrange=[],colors=0,showthese=[],plot=1)` Narrow down the plot from the above\n",
    "\n",
    "`fig=FDCstack(subset,ylims=[0.01,100],subsetname='Subset')` Returns overlayed scaled FDCs for a list of gauges\n",
    "\n",
    "`fig=HydrographStack(subset,ylims=[0.001,10],subsetname='Subset')` Returns overlayed scaled median annual hydrographs for a list of gauges. `HydrographStackSLOW()` is the same but doesn't rely on pre-calculated table.\n",
    " \n",
    "### [Forcing Data Plots](#Forcing-Data)\n",
    "`data=loadforcing(gauge,dataset='daymet')` Loads forcing data (T, precip etc) from chosen dataset.\n",
    " \n",
    "`fig=ForcingMinMedMax(gauge,columnname,dataset='daymet')` Displays plot of period of record min/med/max for forcing value over calendar year \n",
    "\n",
    "`fig=RasterPrecip(gauge,dataset='daymet')` Like the raster hydrograph, but for precipitation\n",
    "\n",
    "`fig=RasterTemps(gauge,'max',dataset='daymet')` Like the raster hydrograph, but for min or max daily temperatures\n",
    "\n",
    "`fig=RollingRasterPrecip(gauge,dataset='daymet',window=30)` Creates a raster plot of the n day sum of precipitation for each day\n",
    "\n",
    "`fig=RollingTypicalPrecip(gauge,dataset='daymet',window=30)`  Gives period of record min/med/max for precipitation over year given a window length\n",
    "\n",
    "`fig=RollingPrcp_select(gauge,selected_years,dataset='daymet',window=30)` As above, but with selected years on top\n",
    "\n",
    "`fig=TypicalTemps(gauge,dataset='daymet')` Plots median daily min/max temperatures for each calendar day and absolute min/max temperatures over period of record\n",
    "\n",
    "`fig=TypicalTemp_selectyear(gauge,selectedyear,dataset='daymet')` Plots a single year's daily T min/max values over the TypicalTemps plot \n",
    "\n",
    "### [Gauge Filtering](#Selected-Gauges-by-Attributes)\n",
    "`acceptable=gaugefilter(subset,column,values)` Standalone, selects gauges within range of values for a field in one of the attribute/signature sets\n",
    "\n",
    "`plotsquare(xrange,yrange,boxtype='k:',label=[])` Plots a box based on an x/y ranges on top of another plot\n",
    "\n",
    "### [Other People's Stuff](#Things-other-people-made-that-are-useful)\n",
    "\n",
    "`shiftedColorMap(cmap, start=0, midpoint=0.5, stop=1.0, name='shiftedcmap')` Shifts a divergent colormap to be re-centered, say to 0\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setting Home folder\n",
    "In this folder, downloaded and expand the CAMELS datasets with the folders:\n",
    "`/basin_timeseries_v1p2_metForcing_obsFlow/`\n",
    "and \n",
    "`/camels_attributes_v2.0/`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#these are just what I have them as, edit them as needed to fit whatever folders you have\n",
    "home = '/Users/DJHeins/Documents/Coding/CAMELS/' \n",
    "processed_data=home+ 'Scripts/CleanedScripts/GitHub/Data/'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setting Pre-requisite Functions / Importing Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "#import math as m\n",
    "\n",
    "def loadflow(gauge):\n",
    "    \"\"\"Returns dataframe directly loading the CAMELS provided streamflow data\"\"\"\n",
    "    gaugeinfo = home + 'basin_timeseries_v1p2_metForcing_obsFlow/basin_dataset_public_v1p2/basin_metadata/gauge_information.txt'\n",
    "    allstreamflows = home + 'basin_timeseries_v1p2_metForcing_obsFlow/basin_dataset_public_v1p2/usgs_streamflow/'\n",
    "    outputs = home+'Scripts/Outputs/'\n",
    "\n",
    "    gauges = pd.read_csv(gaugeinfo,sep='\\t',header=0)  #had to adjust headers to line up right\n",
    "\n",
    "    huc_id=gauges[gauges.GAGE_ID==gauge]['HUC_02'].values[0]\n",
    "\n",
    "    GaugeInfo=gauges[gauges.GAGE_ID==gauge]\n",
    "\n",
    "    if huc_id <10:\n",
    "        nhuc = '0'+str(huc_id)\n",
    "    else:\n",
    "        nhuc = str(huc_id)\n",
    "\n",
    "    streamflows = allstreamflows+nhuc+'/'\n",
    "\n",
    "    if gauge < 10000000:\n",
    "        data=streamflows+'0'+str(gauge)+'_streamflow_qc.txt'\n",
    "    else:\n",
    "        data=streamflows+str(gauge)+'_streamflow_qc.txt'\n",
    "\n",
    "    data=pd.read_csv(data,sep='\\s+',header=None)\n",
    "    return data\n",
    "\n",
    "def FDC(gauge):\n",
    "    \"\"\"Returns dataframe with FDC info - Flow, Count Exceeded, Percent Exceeded\n",
    "    Dependent on loadflow(gauge)\"\"\"\n",
    "    \n",
    "    data=loadflow(gauge)\n",
    "\n",
    "    # Remove any years missing a lot of data\n",
    "    numdays=329 #minimum number of days\n",
    "    fdc_data=data\n",
    "    fdc_data=fdc_data[fdc_data[4] != -999.0] #remove nulls\n",
    "    yr1=min(fdc_data[1].values)\n",
    "    yrEnd=max(fdc_data[1].values)\n",
    "    for year in range(yr1,yrEnd+1):\n",
    "        if np.sum(fdc_data[1]==year)<numdays:\n",
    "            fdc_data=fdc_data[fdc_data[1] != year]\n",
    "\n",
    "    flows=fdc_data[4].values\n",
    "    N=np.size(flows)\n",
    "    P=100*np.append(np.linspace(0,1,100,endpoint=False),[.996,.997,.998,.999,.9999])\n",
    "    threshold=np.percentile(flows,P)\n",
    "    I=np.size(threshold)\n",
    "\n",
    "    A=np.zeros((I,3))\n",
    "    for i in range(0,I):\n",
    "        A[i,0]=threshold[i]\n",
    "        A[i,1]=np.sum(flows>threshold[i])\n",
    "        A[i,2]=100*A[i,1]/N\n",
    "    fdc=pd.DataFrame({'Flow':A[:,0],'Count Exceed':A[:,1],'Percent Exceed':A[:,2]})\n",
    "    return fdc "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# FDC Plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def FDC_breakpoints(gauge, scaled=1):\n",
    "    \"\"\"Finds optimal breakpoint for 2 line representation of FDC, plots it\n",
    "    Dependent on loadflow(gauge)\n",
    "    scaled=1 (default): scales to mean flow\n",
    "    scaled=0: leaves flows in ft^3/s\"\"\"\n",
    "    \n",
    "    upslope_value=90\n",
    "    downslope_value=10\n",
    "    \n",
    "    data=loadflow(gauge)\n",
    "    \n",
    "    # FLOW DURATION CURVE\n",
    "    #removing partial years/nulls \n",
    "    numdays=329 #minimum number of days to be accepted\n",
    "    data=data[data[4] != -999.0] #remove nulls\n",
    "    yr1=min(data[1].values)\n",
    "    yrEnd=max(data[1].values)\n",
    "    for year in range(yr1,yrEnd+1):\n",
    "        if np.sum(data[1]==year)<numdays:\n",
    "            data=data[data[1] != year]\n",
    "\n",
    "    flows=data[4].values\n",
    "\n",
    "    #RUN DRY? \n",
    "    if np.min(flows) == 0:\n",
    "        Dry=1\n",
    "        PctFlow=np.sum(flows!=0)/np.size(flows)\n",
    "        flows=data[data[4]!=0][4].values\n",
    "    else:\n",
    "        Dry=0\n",
    "        PctFlow=100\n",
    "\n",
    "    P=100*np.append(np.linspace(0,1,100,endpoint=False),[.995,.9975,.999,.9999])\n",
    "    threshold=np.percentile(flows,P)\n",
    "    if scaled==1: meanflow = np.mean(flows); modthresh=threshold/meanflow\n",
    "    if scaled==0: modthresh=threshold\n",
    "    fdc=pd.DataFrame({'Flow':threshold,'Scaled Flow':modthresh,'Percent Exceed':100-P})\n",
    "    pct=fdc['Percent Exceed'].values\n",
    "    flw=fdc['Scaled Flow'].values \n",
    "\n",
    "    #ONE LINE PREDICTOR\n",
    "    upslope=flw[pct==upslope_value]\n",
    "    downslope=flw[pct==downslope_value]\n",
    "\n",
    "    m=(np.log(upslope)-np.log(downslope))/(downslope_value-upslope_value)\n",
    "    def slopeprediction(x):\n",
    "        return np.exp(np.log(upslope)-m*(x-upslope_value))\n",
    "\n",
    "    pct_subset=pct[pct>downslope_value][pct[pct>downslope_value]<upslope_value]\n",
    "    predictions_oneline=slopeprediction(pct_subset)\n",
    "    flw_subset=flw[pct>downslope_value][pct[pct>downslope_value]<upslope_value]\n",
    "\n",
    "\n",
    "    #BEST BREAKPOINT DETERMINATION\n",
    "    breakpoint_tests=pct_subset \n",
    "    N_tests=np.size(breakpoint_tests)\n",
    "\n",
    "    def slopeprediction_2(x):\n",
    "        if x >= breakpoint:\n",
    "            return np.exp(np.log(upslope)-m_A*(x-upslope_value))\n",
    "        else:\n",
    "            return np.exp(np.log(breakpoint_flw)-m_B*(x-breakpoint))\n",
    "\n",
    "    out=np.zeros(shape=(N_tests,5))\n",
    "    for index in range(0,N_tests):\n",
    "        breakpoint=breakpoint_tests[index]\n",
    "        breakpoint_flw=flw[pct==breakpoint]\n",
    "        m_A=(np.log(upslope)-np.log(breakpoint_flw))/(breakpoint-upslope_value)\n",
    "        m_B=(np.log(breakpoint_flw)-np.log(downslope))/(downslope_value-breakpoint)\n",
    "\n",
    "        predictions_2=np.zeros(shape=np.shape(flw_subset))\n",
    "        for i in range (0,np.size(flw_subset)):\n",
    "            predictions_2[i]=slopeprediction_2(pct_subset[i])\n",
    "        log_diff_2=np.log(predictions_2)-np.log(flw_subset)\n",
    "        abs_log_diff_2=np.abs(log_diff_2)\n",
    "        error=np.mean(abs_log_diff_2)\n",
    "        error_b=np.mean(log_diff_2)\n",
    "\n",
    "        out[index,0]=breakpoint\n",
    "        out[index,1]=error\n",
    "        out[index,2]=m_A\n",
    "        out[index,3]=m_B\n",
    "        out[index,4]=error_b\n",
    "    out=pd.DataFrame(out,columns=['pct','err','m_A','m_B','err_b'])\n",
    "    true_2line=out[out.err==np.min(out.err)]\n",
    "\n",
    "    true_breakpoint=true_2line.pct.values\n",
    "    meanabsdiff_2line=true_2line.err.values\n",
    "    m_A=true_2line.m_A.values\n",
    "    m_B=true_2line.m_B.values\n",
    "    breakpoint_flw=flw[pct==true_breakpoint]\n",
    "\n",
    "    #PREDICTED VALUES 2 LINES\n",
    "    def slopeprediction_2line(x):\n",
    "        if x >= true_breakpoint:\n",
    "            return np.exp(np.log(upslope)-m_A*(x-upslope_value))\n",
    "        else:\n",
    "            return np.exp(np.log(breakpoint_flw)-m_B*(x-true_breakpoint))\n",
    "    L=np.size(pct_subset)\n",
    "    predictions_2line=np.zeros(shape=(L,1))\n",
    "    for i in range (0,L):\n",
    "        predictions_2line[i]=slopeprediction_2line(pct_subset[i])\n",
    "\n",
    "    #PLOTTING\n",
    "    if Dry == 1:   #rescaling the plot if the catchment runs dry\n",
    "        true_breakpoint=PctFlow*true_breakpoint\n",
    "        pct=PctFlow*pct\n",
    "        pct_subset=PctFlow*pct_subset\n",
    "        upslope_value=PctFlow*upslope_value\n",
    "        downslope_value=PctFlow*downslope_value\n",
    "        \n",
    "    fig=plt.figure()\n",
    "    plt.semilogy(pct,flw,'b-')\n",
    "    plt.semilogy(pct_subset,predictions_oneline,'--')\n",
    "    plt.semilogy(pct_subset,predictions_2line,'c--')\n",
    "    plt.semilogy(upslope_value,upslope,'r*',downslope_value,downslope,'r*',true_breakpoint,breakpoint_flw,'r*')\n",
    "    if scaled==1: plt.ylabel('Daily Average Flow / Period of Record Mean')\n",
    "    if scaled==0: plt.ylabel('Daily Average Flow (ft$^3$/s)')\n",
    "    plt.xlabel('Percentage of Time Flow Exceeded')\n",
    "    plt.title('FDC with Optimal Breakpoint, Gauge '+str(gauge))\n",
    "    axes = plt.gca()\n",
    "    axes.set_xlim([-3,103])\n",
    "    plt.show()\n",
    "    return fig  \n",
    "    \n",
    "def MedianFDC(gauge):\n",
    "    \"\"\"Returns plot of each year's FDC, median of that, and regular FDC\n",
    "    Dependent on loadflow(gauge) and FDC(gauge)\"\"\"\n",
    "\n",
    "    data=loadflow(gauge)\n",
    "    fdc=FDC(gauge)\n",
    "    \n",
    "    # Remove any years missing a lot of data\n",
    "    numdays=329 #minimum number of days\n",
    "    fdc_data=data\n",
    "    fdc_data=fdc_data[fdc_data[4] != -999.0] #remove nulls\n",
    "    yr1=min(fdc_data[1].values)\n",
    "    yrEnd=max(fdc_data[1].values)\n",
    "    for year in range(yr1,yrEnd+1):\n",
    "        if np.sum(fdc_data[1]==year)<numdays:\n",
    "            fdc_data=fdc_data[fdc_data[1] != year]\n",
    "\n",
    "    # FLOW DURATION CURVE EVERY YEAR\n",
    "    yr1=min(fdc_data[1].values)\n",
    "    yrEnd=max(fdc_data[1].values)\n",
    "    years=np.unique(fdc_data[1].values)\n",
    "    P=100*np.linspace(0,1,100,endpoint=False)\n",
    "    I=np.size(P)\n",
    "    nyears=np.size(years)\n",
    "    A=np.zeros((nyears,I))\n",
    "\n",
    "    fig=plt.figure()\n",
    "\n",
    "    for i in range(0,nyears):\n",
    "        year=years[i]\n",
    "        tempdata=fdc_data[fdc_data[1] == year]\n",
    "        flows=tempdata[4].values\n",
    "        N=np.size(flows)\n",
    "        P=100*np.linspace(0,1,100,endpoint=False)\n",
    "        threshold=np.percentile(flows,P)\n",
    "        A[i,:]=threshold\n",
    "        plt.semilogy(100-P,threshold,'c-',alpha=0.3)\n",
    "\n",
    "    medianFDC=np.median(A, axis=0)\n",
    "    plt.semilogy([],[],'c-',label='Individual years')\n",
    "    plt.semilogy(fdc['Percent Exceed'],fdc['Flow'],'b-',label='Period of record FDC')\n",
    "    plt.semilogy(100-P,medianFDC,'r-',label='Median annual FDC')\n",
    "    plt.title('Flow Duration Curve (Daily) at Gauge '+str(gauge))\n",
    "    plt.ylabel('Daily Average Flow ($ft^3$/s)')\n",
    "    plt.xlabel('Percentage of Time Flow Exceeded')\n",
    "    plt.legend() #(bbox_to_anchor=(1.02, 1), loc=2, borderaxespad=0.)\n",
    "    plt.show()\n",
    "    return fig\n",
    "\n",
    "def MedianScaledFDC(gauge):\n",
    "    \"\"\"Returns plot of each year's FDC scaled to annual means, median of that, and regular FDC\n",
    "    Dependent on loadflow(gauge) and FDC(gauge)\"\"\"\n",
    "    \n",
    "    data=loadflow(gauge)\n",
    "    fdc=FDC(gauge)\n",
    "    \n",
    "    # Remove any years missing a lot of data\n",
    "    numdays=329 #minimum number of days\n",
    "    fdc_data=data\n",
    "    fdc_data=fdc_data[fdc_data[4] != -999.0] #remove nulls\n",
    "    yr1=min(fdc_data[1].values)\n",
    "    yrEnd=max(fdc_data[1].values)\n",
    "    for year in range(yr1,yrEnd+1):\n",
    "        if np.sum(fdc_data[1]==year)<numdays:\n",
    "            fdc_data=fdc_data[fdc_data[1] != year]\n",
    "\n",
    "    QBar=fdc_data.mean()[4]\n",
    "\n",
    "    # FLOW DURATION CURVE EVERY YEAR\n",
    "    yr1=min(fdc_data[1].values)\n",
    "    yrEnd=max(fdc_data[1].values)\n",
    "    years=np.unique(fdc_data[1].values)\n",
    "    P=100*np.linspace(0,1,100,endpoint=False)\n",
    "    I=np.size(P)\n",
    "    nyears=np.size(years)\n",
    "    A=np.zeros((nyears,I))\n",
    "    \n",
    "    fig=plt.figure()\n",
    "\n",
    "    for i in range(0,nyears):\n",
    "        year=years[i]\n",
    "        tempdata=fdc_data[fdc_data[1] == year]\n",
    "        flows=tempdata[4].values\n",
    "        \n",
    "        qyear=np.mean(flows)\n",
    "        flows=flows/qyear\n",
    "        \n",
    "        N=np.size(flows)\n",
    "        P=100*np.linspace(0,1,100,endpoint=False)\n",
    "        threshold=np.percentile(flows,P)\n",
    "        A[i,:]=threshold\n",
    "        plt.semilogy(100-P,threshold,'c-',alpha=0.3)\n",
    "\n",
    "    medianFDC=np.median(A, axis=0)\n",
    "    plt.semilogy([],[],'c-',label='Individual years')\n",
    "    plt.semilogy(fdc['Percent Exceed'],fdc['Flow']/QBar,'b-',label='Period of record FDC')\n",
    "    plt.semilogy(100-P,medianFDC,'r-',label='Median annual FDC')\n",
    "    plt.title('Scaled Median FDC, Gauge '+str(gauge))\n",
    "    plt.ylabel('Scaled Daily Average Flow')\n",
    "    plt.xlabel('Percentage of Time Flow Exceeded')\n",
    "    plt.legend(bbox_to_anchor=(1.02, 1), loc=2, borderaxespad=0.)\n",
    "    plt.show()\n",
    "    return fig \n",
    "\n",
    "def PeriodHydrographFDC(gauge):\n",
    "    \"\"\"Plots period of record FDC overlayed on Period Hydrograph\n",
    "    Dependent on loadflow(gauge) and FDC(gauge)\"\"\"\n",
    "\n",
    "    data=loadflow(gauge)\n",
    "    fdc=FDC(gauge)\n",
    "    \n",
    "    # FDC vs Period Hydrograph\n",
    "    fig, ax1 = plt.subplots()\n",
    "    ax1.semilogy(data[4],'c-')\n",
    "    ax1.set_ylabel('Daily Average Flow ($ft^3$/s)')\n",
    "    ax2 = ax1.twiny()  # instantiate a second axes that shares the same x-axis\n",
    "    ax2.semilogy(fdc['Percent Exceed'],fdc['Flow'],'b.-')\n",
    "    ax1.tick_params(axis='x',which='both',bottom=False,top=False,labelbottom=False)\n",
    "    ax2.tick_params(axis='x',which='both',bottom=True,top=False,labelbottom=True,labeltop=False) \n",
    "    plt.title('Flow Duration Curve (Daily) at Gauge '+str(gauge))\n",
    "    #fig.tight_layout()  # otherwise the right y-label is slightly clipped\n",
    "    plt.show()\n",
    "    return fig "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def HydrographFDCOverlay(gauge):\n",
    "    \"\"\"Makes an overlay of the annual hydrograph range and FDC with 1 & 2 line approximations. Code is not cleaned up.\"\"\"\n",
    "    # FDC PART\n",
    "\n",
    "    scaled=0\n",
    "    upslope_value=90\n",
    "    downslope_value=10\n",
    "\n",
    "    data=loadflow(gauge)\n",
    "\n",
    "    # FLOW DURATION CURVE\n",
    "    #removing partial years/nulls \n",
    "    numdays=329 #minimum number of days to be accepted\n",
    "    data=data[data[4] != -999.0] #remove nulls\n",
    "    yr1=min(data[1].values)\n",
    "    yrEnd=max(data[1].values)\n",
    "    for year in range(yr1,yrEnd+1):\n",
    "        if np.sum(data[1]==year)<numdays:\n",
    "            data=data[data[1] != year]\n",
    "\n",
    "    flows=data[4].values\n",
    "\n",
    "    #RUN DRY? \n",
    "    if np.min(flows) == 0:\n",
    "        Dry=1\n",
    "        PctFlow=np.sum(flows!=0)/np.size(flows)\n",
    "        flows=data[data[4]!=0][4].values\n",
    "    else:\n",
    "        Dry=0\n",
    "        PctFlow=100\n",
    "\n",
    "    P=100*np.append(np.linspace(0,1,100,endpoint=False),[.995,.9975,.999,.9999])\n",
    "    threshold=np.percentile(flows,P)\n",
    "    if scaled==1: meanflow = np.mean(flows); modthresh=threshold/meanflow\n",
    "    if scaled==0: modthresh=threshold\n",
    "    fdc=pd.DataFrame({'Flow':threshold,'Scaled Flow':modthresh,'Percent Exceed':100-P})\n",
    "    pct=fdc['Percent Exceed'].values\n",
    "    flw=fdc['Scaled Flow'].values \n",
    "\n",
    "    #ONE LINE PREDICTOR\n",
    "    upslope=flw[pct==upslope_value]\n",
    "    downslope=flw[pct==downslope_value]\n",
    "\n",
    "    m=(np.log(upslope)-np.log(downslope))/(downslope_value-upslope_value)\n",
    "    def slopeprediction(x):\n",
    "        return np.exp(np.log(upslope)-m*(x-upslope_value))\n",
    "\n",
    "    pct_subset=pct[pct>downslope_value][pct[pct>downslope_value]<upslope_value]\n",
    "    predictions_oneline=slopeprediction(pct_subset)\n",
    "    flw_subset=flw[pct>downslope_value][pct[pct>downslope_value]<upslope_value]\n",
    "\n",
    "    #BEST BREAKPOINT DETERMINATION\n",
    "    breakpoint_tests=pct_subset \n",
    "    N_tests=np.size(breakpoint_tests)\n",
    "\n",
    "    def slopeprediction_2(x):\n",
    "        if x >= breakpoint:\n",
    "            return np.exp(np.log(upslope)-m_A*(x-upslope_value))\n",
    "        else:\n",
    "            return np.exp(np.log(breakpoint_flw)-m_B*(x-breakpoint))\n",
    "\n",
    "    out=np.zeros(shape=(N_tests,5))\n",
    "    for index in range(0,N_tests):\n",
    "        breakpoint=breakpoint_tests[index]\n",
    "        breakpoint_flw=flw[pct==breakpoint]\n",
    "        m_A=(np.log(upslope)-np.log(breakpoint_flw))/(breakpoint-upslope_value)\n",
    "        m_B=(np.log(breakpoint_flw)-np.log(downslope))/(downslope_value-breakpoint)\n",
    "\n",
    "        predictions_2=np.zeros(shape=np.shape(flw_subset))\n",
    "        for i in range (0,np.size(flw_subset)):\n",
    "            predictions_2[i]=slopeprediction_2(pct_subset[i])\n",
    "        log_diff_2=np.log(predictions_2)-np.log(flw_subset)\n",
    "        abs_log_diff_2=np.abs(log_diff_2)\n",
    "        error=np.mean(abs_log_diff_2)\n",
    "        error_b=np.mean(log_diff_2)\n",
    "\n",
    "        out[index,0]=breakpoint\n",
    "        out[index,1]=error\n",
    "        out[index,2]=m_A\n",
    "        out[index,3]=m_B\n",
    "        out[index,4]=error_b\n",
    "    out=pd.DataFrame(out,columns=['pct','err','m_A','m_B','err_b'])\n",
    "    true_2line=out[out.err==np.min(out.err)]\n",
    "\n",
    "    true_breakpoint=true_2line.pct.values\n",
    "    meanabsdiff_2line=true_2line.err.values\n",
    "    m_A=true_2line.m_A.values\n",
    "    m_B=true_2line.m_B.values\n",
    "    breakpoint_flw=flw[pct==true_breakpoint]\n",
    "\n",
    "    #PREDICTED VALUES 2 LINES\n",
    "    def slopeprediction_2line(x):\n",
    "        if x >= true_breakpoint:\n",
    "            return np.exp(np.log(upslope)-m_A*(x-upslope_value))\n",
    "        else:\n",
    "            return np.exp(np.log(breakpoint_flw)-m_B*(x-true_breakpoint))\n",
    "    L=np.size(pct_subset)\n",
    "    predictions_2line=np.zeros(shape=(L,1))\n",
    "    for i in range (0,L):\n",
    "        predictions_2line[i]=slopeprediction_2line(pct_subset[i])\n",
    "\n",
    "    #PLOTTING\n",
    "    if Dry == 1:   #rescaling the plot if the catchment runs dry\n",
    "        true_breakpoint=PctFlow*true_breakpoint\n",
    "        pct=PctFlow*pct\n",
    "        pct_subset=PctFlow*pct_subset\n",
    "        upslope_value=PctFlow*upslope_value\n",
    "        downslope_value=PctFlow*downslope_value\n",
    "    #~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
    "    # HYDROGRAPH PART\n",
    "    data=loadflow(gauge)\n",
    "    data=data.replace(-999.0,np.nan)\n",
    "\n",
    "    yrsum= pd.DataFrame(columns=['Month','Day','Median','Min','Max'])\n",
    "    n=0\n",
    "    for month in range(1,13,1):\n",
    "        if month in [9,4,6,11]: #30 \n",
    "            for day in range(1,31):\n",
    "                yrsum.loc[n,'Month']=month\n",
    "                yrsum.loc[n,'Day']=day\n",
    "                yrsum.loc[n,'Median']=data[(data[3]==day) & (data[2]==month)][4].median()\n",
    "                yrsum.loc[n,'Min']=data[(data[3]==day) & (data[2]==month)][4].min()\n",
    "                yrsum.loc[n,'Max']=data[(data[3]==day) & (data[2]==month)][4].max()\n",
    "                n=n+1\n",
    "        if month in [1,3,5,7,8,10,12]: #31\n",
    "            for day in range(1,32):\n",
    "                yrsum.loc[n,'Month']=month\n",
    "                yrsum.loc[n,'Day']=day\n",
    "                yrsum.loc[n,'Median']=data[(data[3]==day) & (data[2]==month)][4].median()\n",
    "                yrsum.loc[n,'Min']=data[(data[3]==day) & (data[2]==month)][4].min()\n",
    "                yrsum.loc[n,'Max']=data[(data[3]==day) & (data[2]==month)][4].max()\n",
    "                n=n+1\n",
    "        if month == 2: #stupid february\n",
    "            for day in range(1,29):\n",
    "                yrsum.loc[n,'Month']=month\n",
    "                yrsum.loc[n,'Day']=day\n",
    "                yrsum.loc[n,'Median']=data[(data[3]==day) & (data[2]==month)][4].median()\n",
    "                yrsum.loc[n,'Min']=data[(data[3]==day) & (data[2]==month)][4].min()\n",
    "                yrsum.loc[n,'Max']=data[(data[3]==day) & (data[2]==month)][4].max()\n",
    "                n=n+1\n",
    "\n",
    "    #~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
    "    # PLOTTING PART            \n",
    "\n",
    "    fig, ax1 = plt.subplots()\n",
    "\n",
    "    ax1.semilogy(yrsum['Max'],'k:',alpha=0.3,label='Max at Date')\n",
    "    ax1.semilogy(yrsum['Median'],'k-',alpha=0.3,label='Median at Date')\n",
    "    ax1.semilogy(yrsum['Min'],'k:',alpha=0.3,label='Min at Date')\n",
    "    plt.legend(bbox_to_anchor=(1.02, 0.75), loc=2, borderaxespad=0.)\n",
    "    #plt.title('Annual Variations in Streamflow at Gauge '+str(gauge))\n",
    "    ax1.set_ylabel('Flow ($ft^3$/s)')\n",
    "    xticklabels=['Jan','Feb','Mar','Apr','May','Jun','Jul','Aug','Sep','Oct','Nov','Dec']\n",
    "    ax1.set_xticks([15,45,74,105,135,166,196,227,258,288,319,349],minor=False)\n",
    "    ax1.set_xticks([0,31,59,90,120,151,181,212,243,273,304,334,365],minor=True)\n",
    "    ax1.set_xticklabels(xticklabels)\n",
    "    ax1.tick_params(axis='x',which='major',bottom=False,top=False,labelbottom=True)\n",
    "    ax1.tick_params(axis='x',which='minor',bottom=True,top=False,labelbottom=False,width=-.5,length=18)\n",
    "\n",
    "    ax2 = ax1.twiny()  # instantiate a second axes that shares the same x-axis\n",
    "    ax2.semilogy(pct,flw,'b-',label='FDC')\n",
    "    ax2.semilogy(pct_subset,predictions_oneline,'--',label='90-10 Straight Line')\n",
    "    ax2.semilogy(pct_subset,predictions_2line,'c--',label='2 Line Approximation')\n",
    "    ax2.semilogy(upslope_value,upslope,'r*',downslope_value,downslope,'r*',true_breakpoint,breakpoint_flw,'r*')\n",
    "    if scaled==1: plt.ylabel('Daily Average Flow / Period of Record Mean')\n",
    "    #if scaled==0: plt.ylabel('Daily Average Flow (ft$^3$/s)')\n",
    "    plt.xlabel('Percentage of Time Flow Exceeded')\n",
    "    #plt.title('FDC with Optimal Breakpoint, Gauge '+str(gauge))\n",
    "    #axes = plt.gca()\n",
    "    ax2.set_xlim([-3,103])\n",
    "    plt.title('FDC & Typical Hydrograph at Gauge '+str(gauge), pad=35)\n",
    "    plt.legend(bbox_to_anchor=(1.02, 1), loc=2, borderaxespad=0.)\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Other Streamflow Plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def RasterHydrograph(gauge):\n",
    "    \"\"\"Return image of raster hydrograph, with no data in black\n",
    "    Dependent on loadflow(gauge)\"\"\"\n",
    "    \n",
    "    data=loadflow(gauge)\n",
    "    data=data.replace(-999.0,np.nan)\n",
    "    if data[2][0] != 1 | data[3][0] != 1:  #if a data doesn't start at Jan 1st, toss that year\n",
    "        display('Note: raster hydrograph removed incomplete year '+str(data[1][0]))\n",
    "        data=data[data[1] != data[1][0]]\n",
    "        \n",
    "    Years=data[1].unique()\n",
    "    NYears=np.size(Years)\n",
    "    RastHydr = np.empty([NYears,365])\n",
    "    StartYear=Years[0]\n",
    "    EndYear=Years[NYears-1]\n",
    "\n",
    "    for nyear in range(0,NYears):\n",
    "        yrdata=data[data[1]==Years[nyear]][4].values\n",
    "        if np.size(yrdata)==366: #leap years are a pain, let's just delete feb 29 from all years \n",
    "            yrdata=np.delete(yrdata,59)\n",
    "        if np.size(yrdata)==365:\n",
    "            RastHydr[nyear,:]=yrdata\n",
    "        else:\n",
    "            RastHydr[nyear,:]=np.full((1,365),np.nan)\n",
    "            display('Note: raster hydrograph removed incomplete year '+str(Years[nyear]))\n",
    "\n",
    "    RHscaled=np.log10(RastHydr+0.001) #making 0 flow days not break the log scale\n",
    "\n",
    "    fig=plt.figure()\n",
    "\n",
    "    Blues2=plt.cm.Blues\n",
    "    Blues2.set_bad('black',1.)\n",
    "\n",
    "    imgplot=plt.imshow(RHscaled,interpolation='nearest', aspect='auto') #,extent=[0,25,0,20])\n",
    "    imgplot.set_cmap(Blues2)\n",
    "    plt.title('Daily Flow at Gauge '+str(gauge)+', '+str(StartYear)+'-'+str(EndYear))\n",
    "    plt.colorbar(label='log10(daily average flow in  $ft^3$/s)')\n",
    "    plt.tick_params(\n",
    "        axis='x',          # changes apply to the x-axis\n",
    "        which='major',      # both major and minor ticks are affected\n",
    "        bottom=False,      # ticks along the bottom edge are off\n",
    "        top=False,         # ticks along the top edge are off\n",
    "        labelbottom=True) # labels along the bottom edge are off\n",
    "\n",
    "    xticklabels=['Jan','Feb','Mar','Apr','May','Jun','Jul','Aug','Sep','Oct','Nov','Dec']\n",
    "    plt.xticks([15,45,74,105,135,166,196,227,258,288,319,349], xticklabels)\n",
    "    labelnum=range(0,NYears,2)\n",
    "    yticklabels=np.ones(np.size(labelnum),dtype=np.int16)\n",
    "    for n in range(0,np.size(labelnum)):\n",
    "        yticklabels[n]=StartYear+labelnum[n]\n",
    "    plt.yticks(range(0,NYears,2), yticklabels)\n",
    "    plt.show()\n",
    "    return fig \n",
    "\n",
    "def StackedHydrograph(gauge):\n",
    "    \"\"\"Returns plot of each year's hydrograph year with min/med/max values for each day\n",
    "    Dependent on loadflow(gauge)\"\"\"\n",
    "\n",
    "    data=loadflow(gauge)\n",
    "    data=data.replace(-999.0,np.nan)\n",
    "\n",
    "    # Remove any years missing a lot of data\n",
    "    numdays=329 #minimum number of days\n",
    "    fdc_data=data\n",
    "    fdc_data=fdc_data[fdc_data[4] != -999.0] #remove nulls\n",
    "    yr1=min(fdc_data[1].values)\n",
    "    yrEnd=max(fdc_data[1].values)\n",
    "    for year in range(yr1,yrEnd+1):\n",
    "        if np.sum(fdc_data[1]==year)<numdays:\n",
    "            fdc_data=fdc_data[fdc_data[1] != year]\n",
    "\n",
    "    yr1=min(fdc_data[1].values)\n",
    "    yrEnd=max(fdc_data[1].values)\n",
    "    years=np.unique(fdc_data[1].values)\n",
    "    P=100*np.linspace(0,1,100,endpoint=False)\n",
    "    I=np.size(P)\n",
    "    nyears=np.size(years)\n",
    "    A=np.zeros((nyears,I))\n",
    "\n",
    "    yrsum= pd.DataFrame(columns=['Month','Day','Median','Min','Max'])\n",
    "    n=0\n",
    "    for month in range(1,13,1):\n",
    "        if month in [9,4,6,11]: #30 \n",
    "            for day in range(1,31):\n",
    "                yrsum.loc[n,'Month']=month\n",
    "                yrsum.loc[n,'Day']=day\n",
    "                yrsum.loc[n,'Median']=data[(data[3]==day) & (data[2]==month)][4].median()\n",
    "                yrsum.loc[n,'Min']=data[(data[3]==day) & (data[2]==month)][4].min()\n",
    "                yrsum.loc[n,'Max']=data[(data[3]==day) & (data[2]==month)][4].max()\n",
    "                n=n+1\n",
    "        if month in [1,3,5,7,8,10,12]: #31\n",
    "            for day in range(1,32):\n",
    "                yrsum.loc[n,'Month']=month\n",
    "                yrsum.loc[n,'Day']=day\n",
    "                yrsum.loc[n,'Median']=data[(data[3]==day) & (data[2]==month)][4].median()\n",
    "                yrsum.loc[n,'Min']=data[(data[3]==day) & (data[2]==month)][4].min()\n",
    "                yrsum.loc[n,'Max']=data[(data[3]==day) & (data[2]==month)][4].max()\n",
    "                n=n+1\n",
    "        if month == 2: #stupid february\n",
    "            for day in range(1,29):\n",
    "                yrsum.loc[n,'Month']=month\n",
    "                yrsum.loc[n,'Day']=day\n",
    "                yrsum.loc[n,'Median']=data[(data[3]==day) & (data[2]==month)][4].median()\n",
    "                yrsum.loc[n,'Min']=data[(data[3]==day) & (data[2]==month)][4].min()\n",
    "                yrsum.loc[n,'Max']=data[(data[3]==day) & (data[2]==month)][4].max()\n",
    "                n=n+1\n",
    "    fig=plt.figure()\n",
    "\n",
    "    fig, ax1 = plt.subplots()\n",
    "\n",
    "    for i in range(0,nyears):\n",
    "        year=years[i]\n",
    "        tempdata=fdc_data[fdc_data[1] == year]\n",
    "        flows=tempdata[4].values\n",
    "        plt.semilogy(flows,'c-',alpha=0.3)\n",
    "    ax1.semilogy(yrsum['Max'],'b-',label='Max',alpha=0.5)\n",
    "    ax1.semilogy(yrsum['Median'],'k-',label='Median',alpha=0.7)\n",
    "    ax1.semilogy(yrsum['Min'],'r-',label='Min',alpha=0.5)\n",
    "    ax1.semilogy([],'c-',label='Individual Years',alpha=0.3)\n",
    "    plt.legend(bbox_to_anchor=(1.02, 1), loc=2, borderaxespad=0.)\n",
    "    plt.title('Annual Variations in Streamflow at Gauge '+str(gauge))\n",
    "    ax1.set_ylabel('Flow ($ft^3$/s)')\n",
    "    xticklabels=['Jan','Feb','Mar','Apr','May','Jun','Jul','Aug','Sep','Oct','Nov','Dec']\n",
    "    ax1.set_xticks([15,45,74,105,135,166,196,227,258,288,319,349],minor=False)\n",
    "    ax1.set_xticks([0,31,59,90,120,151,181,212,243,273,304,334,365],minor=True)\n",
    "    ax1.set_xticklabels(xticklabels)\n",
    "    ax1.tick_params(axis='x',which='major',bottom=False,top=False,labelbottom=True)\n",
    "    ax1.tick_params(axis='x',which='minor',bottom=True,top=False,labelbottom=False,width=-.5,length=18)\n",
    "    plt.show()\n",
    "    return fig\n",
    "\n",
    "def TypicalYear(gauge):\n",
    "    \"\"\"Returns plot of typical year with min/med/max values for each day\n",
    "    Dependent on loadflow(gauge)\"\"\"\n",
    "   \n",
    "    data=loadflow(gauge)\n",
    "    data=data.replace(-999.0,np.nan)\n",
    "\n",
    "    yrsum= pd.DataFrame(columns=['Month','Day','Median','Min','Max'])\n",
    "    n=0\n",
    "    for month in range(1,13,1):\n",
    "        if month in [9,4,6,11]: #30 \n",
    "            for day in range(1,31):\n",
    "                yrsum.loc[n,'Month']=month\n",
    "                yrsum.loc[n,'Day']=day\n",
    "                yrsum.loc[n,'Median']=data[(data[3]==day) & (data[2]==month)][4].median()\n",
    "                yrsum.loc[n,'Min']=data[(data[3]==day) & (data[2]==month)][4].min()\n",
    "                yrsum.loc[n,'Max']=data[(data[3]==day) & (data[2]==month)][4].max()\n",
    "                n=n+1\n",
    "        if month in [1,3,5,7,8,10,12]: #31\n",
    "            for day in range(1,32):\n",
    "                yrsum.loc[n,'Month']=month\n",
    "                yrsum.loc[n,'Day']=day\n",
    "                yrsum.loc[n,'Median']=data[(data[3]==day) & (data[2]==month)][4].median()\n",
    "                yrsum.loc[n,'Min']=data[(data[3]==day) & (data[2]==month)][4].min()\n",
    "                yrsum.loc[n,'Max']=data[(data[3]==day) & (data[2]==month)][4].max()\n",
    "                n=n+1\n",
    "        if month == 2: #stupid february\n",
    "            for day in range(1,29):\n",
    "                yrsum.loc[n,'Month']=month\n",
    "                yrsum.loc[n,'Day']=day\n",
    "                yrsum.loc[n,'Median']=data[(data[3]==day) & (data[2]==month)][4].median()\n",
    "                yrsum.loc[n,'Min']=data[(data[3]==day) & (data[2]==month)][4].min()\n",
    "                yrsum.loc[n,'Max']=data[(data[3]==day) & (data[2]==month)][4].max()\n",
    "                n=n+1\n",
    "\n",
    "    fig, ax1 = plt.subplots()\n",
    "    \n",
    "    ax1.semilogy(yrsum['Max'],'b-',label='Max')\n",
    "    ax1.semilogy(yrsum['Median'],'k-',label='Median')\n",
    "    ax1.semilogy(yrsum['Min'],'r-',label='Min')\n",
    "    plt.legend() #(bbox_to_anchor=(1.02, 1), loc=2, borderaxespad=0.)\n",
    "    plt.title('Annual Variations in Streamflow at Gauge '+str(gauge))\n",
    "    ax1.set_ylabel('Flow ($ft^3$/s)')\n",
    "    xticklabels=['Jan','Feb','Mar','Apr','May','Jun','Jul','Aug','Sep','Oct','Nov','Dec']\n",
    "    ax1.set_xticks([15,45,74,105,135,166,196,227,258,288,319,349],minor=False)\n",
    "    ax1.set_xticks([0,31,59,90,120,151,181,212,243,273,304,334,365],minor=True)\n",
    "    ax1.set_xticklabels(xticklabels)\n",
    "    ax1.tick_params(axis='x',which='major',bottom=False,top=False,labelbottom=True)\n",
    "    ax1.tick_params(axis='x',which='minor',bottom=True,top=False,labelbottom=False,width=-.5,length=18)\n",
    "    plt.show()\n",
    "    return fig \n",
    "\n",
    "def multiplot(gauge):\n",
    "    \"\"\"plots MapMaker,TypicalYear,RasterHydrograph, & PeriodHydrographFDC for a gauge\"\"\"\n",
    "    fig=MapMaker(gauge)\n",
    "    fig=TypicalYear(gauge)\n",
    "    fig=RasterHydrograph(gauge)\n",
    "    fig=PeriodHydrographFDC(gauge)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# I'M THE MAP!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "def CONUSplot():\n",
    "    \"\"\"Makes a plot of the continental US, can be plotted over\"\"\" \n",
    "    \n",
    "    #add needed libraries\n",
    "    import matplotlib.patches as mpatches\n",
    "    import shapely.geometry as sgeom\n",
    "    import cartopy.crs as ccrs\n",
    "    import cartopy.io.shapereader as shpreader\n",
    "    \n",
    "    #set domain\n",
    "    ax = plt.axes([0.01, 0.01, 0.98, 0.98], projection=ccrs.PlateCarree())\n",
    "    ax.set_xlim([-125, -66.5]); ax.set_ylim([23, 50])\n",
    "    \n",
    "    #load shapefiles\n",
    "    shapename = 'admin_1_states_provinces_lakes_shp'\n",
    "    states_shp = shpreader.natural_earth(resolution='110m', category='cultural', name=shapename)\n",
    "    \n",
    "    # turn off the outline and background patches\n",
    "    ax.background_patch.set_visible(False)\n",
    "    ax.outline_patch.set_visible(False)\n",
    "    \n",
    "    #plot each state\n",
    "    for state in shpreader.Reader(states_shp).geometries():\n",
    "        facecolor = [0.95, 0.95, 0.95]\n",
    "        edgecolor = 'grey'\n",
    "        ax.add_geometries([state], ccrs.PlateCarree(),facecolor=facecolor, edgecolor=edgecolor)\n",
    "        \n",
    "def MapMaker(gauge):\n",
    "    \"\"\"Returns map of CONUS with red dot at gauge location\n",
    "    dependent on CONUSplot()\"\"\"\n",
    "    \n",
    "    gaugeinfo = home + 'basin_timeseries_v1p2_metForcing_obsFlow/basin_dataset_public_v1p2/basin_metadata/gauge_information.txt'\n",
    "\n",
    "    gauges = pd.read_csv(gaugeinfo,sep='\\t',header=0)  #had to adjust headers to line up right\n",
    "    huc_id=gauges[gauges.GAGE_ID==gauge]['HUC_02'].values[0]\n",
    "\n",
    "    GaugeInfo=gauges[gauges.GAGE_ID==gauge]\n",
    "\n",
    "    [lat,lon]=[GaugeInfo['LAT'].values,GaugeInfo['LONG'].values] #identifying gauge coordinates\n",
    "    fig=plt.figure()\n",
    "    CONUSplot() #add plot of USA\n",
    "    plt.plot(lon,lat,'ro')\n",
    "    plt.title('Gauge '+str(gauge))\n",
    "\n",
    "    plt.show()\n",
    "    return fig \n",
    "\n",
    "def mapdata(category,column,colorscale='divergent',gauge=[],subset=[],show=1,figon=1,size=15):\n",
    "    \"\"\"Plots map with colorscaled dots\n",
    "    category:  'name','geol','clim','hydro','soil','topo','vege','OtherAnalysis','fdc_info' \n",
    "    column: column name from above dataset\n",
    "    gauge: Can highlight individual gauge on map, optional/off by default\n",
    "    subset: Can narrow to subset of gauges with a *list* of gauge IDs\n",
    "    show: 1 if make a figure as is, 0 if want to modify it\n",
    "    colorscale: decide color system\n",
    "        'linear', 'divergent', or 'custom'\n",
    "        if custom: col, shiftedcmap = customcolors() ...must be defined prior \"\"\"\n",
    "    fdc_infoALL=returnattributeset('fdc_info')\n",
    "    if subset==[]:   subset=fdc_infoALL.gauge\n",
    "    category=returnattributeset(category)\n",
    "    df1=fdc_infoALL[fdc_infoALL.gauge.isin(subset)][['gauge','LAT','LONG']]\n",
    "    df2=category[fdc_infoALL.gauge.isin(subset)][[column]]\n",
    "    df1=pd.concat([df1, df2], axis=1)\n",
    "\n",
    "    gaugeinfo = home + 'basin_timeseries_v1p2_metForcing_obsFlow/basin_dataset_public_v1p2/basin_metadata/gauge_information.txt'\n",
    "\n",
    "    if figon==1: fig=plt.figure(figsize=(8,6))\n",
    "    CONUSplot()\n",
    "\n",
    "    col=df1[column]\n",
    "    if colorscale=='divergent':\n",
    "        colormap=plt.cm.coolwarm_r\n",
    "        colorscaledata=col\n",
    "        cmapmidpoint=1-max(colorscaledata)/(max(colorscaledata)+abs(min(colorscaledata)))\n",
    "        shiftedcmap=shiftedColorMap(colormap, start=0, midpoint=cmapmidpoint, stop=1, name='shiftedcmap')\n",
    "    if colorscale=='linear':\n",
    "        shiftedcmap= plt.cm.viridis_r #Blues #inferno_r #\n",
    "    if colorscale=='PctFlow':\n",
    "        subsetZ_B=returnattributeset('fdc_info')\n",
    "        col=subsetZ_B['PctFlow']\n",
    "        colormap= plt.cm.plasma_r\n",
    "        colorscaledata=col\n",
    "        shiftedcmap=shiftedColorMap(colormap, start=-0.2, midpoint=.98, stop=1, name='shiftedcmap')\n",
    "        colorbarlabel='Percentage of days with flow'\n",
    "\n",
    "    plt.set_cmap(shiftedcmap)\n",
    "    plt.scatter(df1['LONG'],df1['LAT'],zorder=2,c=col,s=size,edgecolor='k',linewidths=0.25)  #zorder apparently puts it on top\n",
    "    plt.colorbar(shrink=0.4,aspect=15,label=column)\n",
    "    if gauge!=[]:\n",
    "        details=df1[df1['gauge']==gauge]\n",
    "        plt.scatter(details['LONG'],details['LAT'],zorder=3,s=40,facecolors='none',edgecolor='k',linewidth=1.5)\n",
    "    if show==1: \n",
    "        plt.show()\n",
    "        return fig"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plots to Emphasize Selected Years"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def MedianFDC_selectyears(gauge,selected_years):\n",
    "    \"\"\"Returns plot specific year FDCs over all FDCs, median FDC, and regular FDC \n",
    "    Dependent on loadflow(gauge) and FDC(gauge)\"\"\"\n",
    "\n",
    "    data=loadflow(gauge)\n",
    "    fdc=FDC(gauge)\n",
    "    \n",
    "    # Remove any years missing a lot of data\n",
    "    numdays=329 #minimum number of days\n",
    "    fdc_data=data\n",
    "    fdc_data=fdc_data[fdc_data[4] != -999.0] #remove nulls\n",
    "    yr1=min(fdc_data[1].values)\n",
    "    yrEnd=max(fdc_data[1].values)\n",
    "    for year in range(yr1,yrEnd+1):\n",
    "        if np.sum(fdc_data[1]==year)<numdays:\n",
    "            fdc_data=fdc_data[fdc_data[1] != year]\n",
    "\n",
    "    # FLOW DURATION CURVE EVERY YEAR\n",
    "    yr1=min(fdc_data[1].values)\n",
    "    yrEnd=max(fdc_data[1].values)\n",
    "    years=np.unique(fdc_data[1].values)\n",
    "    P=100*np.linspace(0,1,100,endpoint=False)\n",
    "    I=np.size(P)\n",
    "    nyears=np.size(years)\n",
    "    A=np.zeros((nyears,I))\n",
    "\n",
    "    fig=plt.figure()\n",
    "\n",
    "    for i in range(0,nyears):\n",
    "        year=years[i]\n",
    "        tempdata=fdc_data[fdc_data[1] == year]\n",
    "        flows=tempdata[4].values\n",
    "        N=np.size(flows)\n",
    "        P=100*np.linspace(0,1,100,endpoint=False)\n",
    "        threshold=np.percentile(flows,P)\n",
    "        A[i,:]=threshold\n",
    "        plt.semilogy(100-P,threshold,'c-',alpha=0.2)\n",
    "\n",
    "    medianFDC=np.median(A, axis=0)\n",
    "    plt.semilogy([],[],'c-',label='Individual years')\n",
    "    plt.semilogy(fdc['Percent Exceed'],fdc['Flow'],'b-',label='Period of record FDC',alpha=0.5)\n",
    "    plt.semilogy(100-P,medianFDC,'r-',label='Median annual FDC',alpha=0.5)\n",
    "\n",
    "    for year in selected_years:\n",
    "        tempdata=fdc_data[fdc_data[1] == year]\n",
    "        flows=tempdata[4].values\n",
    "        N=np.size(flows)\n",
    "        P=100*np.linspace(0,1,100,endpoint=False)\n",
    "        threshold=np.percentile(flows,P)\n",
    "        A[i,:]=threshold\n",
    "        plt.semilogy(100-P,threshold,'-',linewidth=2,label=str(year))\n",
    "        \n",
    "    plt.title('Flow Duration Curve (Daily) at Gauge '+str(gauge))\n",
    "    plt.ylabel('Daily Average Flow ($ft^3$/s)')\n",
    "    plt.xlabel('Percentage of Time Flow Exceeded')\n",
    "    plt.legend(bbox_to_anchor=(1.02, 1), loc=2, borderaxespad=0.)\n",
    "    plt.show()\n",
    "    \n",
    "    return fig\n",
    "\n",
    "def MedianScaledFDC_selectyears(gauge,selected_years):\n",
    "    \"\"\"Returns plot specific year scaled FDCs over all scaled FDCs, median FDC, and regular FDC \n",
    "    Dependent on loadflow(gauge) and FDC(gauge)\"\"\"\n",
    "    \n",
    "    data=loadflow(gauge)\n",
    "    fdc=FDC(gauge)\n",
    "    \n",
    "    # Remove any years missing a lot of data\n",
    "    numdays=329 #minimum number of days\n",
    "    fdc_data=data\n",
    "    fdc_data=fdc_data[fdc_data[4] != -999.0] #remove nulls\n",
    "    yr1=min(fdc_data[1].values)\n",
    "    yrEnd=max(fdc_data[1].values)\n",
    "    for year in range(yr1,yrEnd+1):\n",
    "        if np.sum(fdc_data[1]==year)<numdays:\n",
    "            fdc_data=fdc_data[fdc_data[1] != year]\n",
    "\n",
    "    QBar=fdc_data.mean()[4]\n",
    "\n",
    "    # FLOW DURATION CURVE EVERY YEAR\n",
    "    yr1=min(fdc_data[1].values)\n",
    "    yrEnd=max(fdc_data[1].values)\n",
    "    years=np.unique(fdc_data[1].values)\n",
    "    P=100*np.linspace(0,1,100,endpoint=False)\n",
    "    I=np.size(P)\n",
    "    nyears=np.size(years)\n",
    "    A=np.zeros((nyears,I))\n",
    "    \n",
    "    fig=plt.figure()\n",
    "\n",
    "    for i in range(0,nyears):\n",
    "        year=years[i]\n",
    "        tempdata=fdc_data[fdc_data[1] == year]\n",
    "        flows=tempdata[4].values\n",
    "        \n",
    "        qyear=np.mean(flows)\n",
    "        flows=flows/qyear\n",
    "        \n",
    "        N=np.size(flows)\n",
    "        P=100*np.linspace(0,1,100,endpoint=False)\n",
    "        threshold=np.percentile(flows,P)\n",
    "        A[i,:]=threshold\n",
    "        plt.semilogy(100-P,threshold,'c-',alpha=0.2)\n",
    "\n",
    "    medianFDC=np.median(A, axis=0)\n",
    "    plt.semilogy([],[],'c-',label='Individual years')\n",
    "    plt.semilogy(fdc['Percent Exceed'],fdc['Flow']/QBar,'b-',label='Period of record FDC',alpha=0.5)\n",
    "    plt.semilogy(100-P,medianFDC,'r-',label='Median annual FDC',alpha=0.5)\n",
    "    \n",
    "    for year in selected_years:\n",
    "        tempdata=fdc_data[fdc_data[1] == year]\n",
    "        flows=tempdata[4].values\n",
    "        qyear=np.mean(flows)\n",
    "        flows=flows/qyear        \n",
    "        N=np.size(flows)\n",
    "        P=100*np.linspace(0,1,100,endpoint=False)\n",
    "        threshold=np.percentile(flows,P)\n",
    "        A[i,:]=threshold\n",
    "        plt.semilogy(100-P,threshold,'-',linewidth=2,label=str(year))\n",
    "        \n",
    "    plt.title('Scaled Median FDC, Gauge '+str(gauge))\n",
    "    plt.ylabel('Scaled Daily Average Flow')\n",
    "    plt.xlabel('Percentage of Time Flow Exceeded')\n",
    "    plt.legend(bbox_to_anchor=(1.02, 1), loc=2, borderaxespad=0.)\n",
    "    plt.show()\n",
    "    return fig \n",
    "\n",
    "def TypicalYear_selectyears(gauge,selected_years):\n",
    "    \"\"\"Returns hydrograph of chosen years over period of record min/med/max \n",
    "    Dependent on loadflow(gauge)\"\"\"\n",
    "\n",
    "    data=loadflow(gauge)\n",
    "    data=data.replace(-999.0,np.nan)\n",
    "\n",
    "    yrsum= pd.DataFrame(columns=['Month','Day','Median','Min','Max'])\n",
    "    n=0\n",
    "    for month in range(1,13,1):\n",
    "        if month in [9,4,6,11]: #30 \n",
    "            for day in range(1,31):\n",
    "                yrsum.loc[n,'Month']=month\n",
    "                yrsum.loc[n,'Day']=day\n",
    "                yrsum.loc[n,'Median']=data[(data[3]==day) & (data[2]==month)][4].median()\n",
    "                yrsum.loc[n,'Min']=data[(data[3]==day) & (data[2]==month)][4].min()\n",
    "                yrsum.loc[n,'Max']=data[(data[3]==day) & (data[2]==month)][4].max()\n",
    "                n=n+1\n",
    "        if month in [1,3,5,7,8,10,12]: #31\n",
    "            for day in range(1,32):\n",
    "                yrsum.loc[n,'Month']=month\n",
    "                yrsum.loc[n,'Day']=day\n",
    "                yrsum.loc[n,'Median']=data[(data[3]==day) & (data[2]==month)][4].median()\n",
    "                yrsum.loc[n,'Min']=data[(data[3]==day) & (data[2]==month)][4].min()\n",
    "                yrsum.loc[n,'Max']=data[(data[3]==day) & (data[2]==month)][4].max()\n",
    "                n=n+1\n",
    "        if month == 2: #stupid february\n",
    "            for day in range(1,29):\n",
    "                yrsum.loc[n,'Month']=month\n",
    "                yrsum.loc[n,'Day']=day\n",
    "                yrsum.loc[n,'Median']=data[(data[3]==day) & (data[2]==month)][4].median()\n",
    "                yrsum.loc[n,'Min']=data[(data[3]==day) & (data[2]==month)][4].min()\n",
    "                yrsum.loc[n,'Max']=data[(data[3]==day) & (data[2]==month)][4].max()\n",
    "                n=n+1\n",
    "\n",
    "    fig, ax1 = plt.subplots()\n",
    "\n",
    "    ax1.semilogy(yrsum['Max'],'b-',label='Max',alpha=0.2)\n",
    "    ax1.semilogy(yrsum['Median'],'k-',label='Median',alpha=0.2)\n",
    "    ax1.semilogy(yrsum['Min'],'r-',label='Min',alpha=0.2)\n",
    "\n",
    "    for year in selected_years:\n",
    "        tempdata=data[data[1] == year]\n",
    "        ax1.semilogy(range(0,365),tempdata[4],'-',label=str(year))\n",
    "\n",
    "    plt.legend(bbox_to_anchor=(1.02, 1), loc=2, borderaxespad=0.)\n",
    "    plt.title('Annual Variations in Streamflow at Gauge '+str(gauge))\n",
    "\n",
    "\n",
    "    ax1.set_ylabel('Flow ($ft^3$/s)')\n",
    "    xticklabels=['Jan','Feb','Mar','Apr','May','Jun','Jul','Aug','Sep','Oct','Nov','Dec']\n",
    "    ax1.set_xticks([15,45,74,105,135,166,196,227,258,288,319,349],minor=False)\n",
    "    ax1.set_xticks([0,31,59,90,120,151,181,212,243,273,304,334,365],minor=True)\n",
    "    ax1.set_xticklabels(xticklabels)\n",
    "    ax1.tick_params(axis='x',which='major',bottom=False,top=False,labelbottom=True)\n",
    "    ax1.tick_params(axis='x',which='minor',bottom=True,top=False,labelbottom=False,width=-.5,length=18)\n",
    "    plt.show()\n",
    "    return fig "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Returning Attribute Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def returnattributes(gauge):\n",
    "    \"\"\"Displays all CAMELS provided attributes for a gauge, along with two sets of calculated streamflow figures\"\"\"\n",
    "    \n",
    "    folder=home+'camels_attributes_v2.0/'; \n",
    "    atttype='name'; filename= folder+'camels_'+atttype+'.txt'; name_ALL= pd.read_csv(filename,sep=';',header=0); name=name_ALL[name_ALL.gauge_id==gauge]; \n",
    "    atttype='geol'; filename= folder+'camels_'+atttype+'.txt'; geol_ALL= pd.read_csv(filename,sep=';',header=0); geol=geol_ALL[geol_ALL.gauge_id==gauge]; \n",
    "    atttype='clim'; filename= folder+'camels_'+atttype+'.txt'; clim_ALL= pd.read_csv(filename,sep=';',header=0); clim=clim_ALL[clim_ALL.gauge_id==gauge]; \n",
    "    atttype='hydro'; filename= folder+'camels_'+atttype+'.txt'; hydro_ALL= pd.read_csv(filename,sep=';',header=0); hydro=hydro_ALL[hydro_ALL.gauge_id==gauge]; \n",
    "    atttype='soil'; filename= folder+'camels_'+atttype+'.txt'; soil_ALL= pd.read_csv(filename,sep=';',header=0); soil=soil_ALL[soil_ALL.gauge_id==gauge]; \n",
    "    atttype='topo'; filename= folder+'camels_'+atttype+'.txt'; topo_ALL= pd.read_csv(filename,sep=';',header=0); topo=topo_ALL[topo_ALL.gauge_id==gauge]; \n",
    "    atttype='vege'; filename= folder+'camels_'+atttype+'.txt'; vege_ALL= pd.read_csv(filename,sep=';',header=0); vege=vege_ALL[vege_ALL.gauge_id==gauge]; \n",
    "\n",
    "    filepath=processed_data+'GaugeSummaryV6.txt'; \n",
    "    OtherAnalysis= pd.read_csv(filepath,sep='\\t',header=0); \n",
    "    OtherAnalysis_ALL=OtherAnalysis[['Gauge','HUC2','Years','Mean','Std','sd_Qann-QBar','sd_Qmon-Qann','sd_Qday-Qmon','Med','fdc20','fdc80','AREA_(KM^2)']]; \n",
    "    OtherAnalysis=OtherAnalysis_ALL[OtherAnalysis_ALL.Gauge==gauge]; \n",
    "\n",
    "    filepath=processed_data+'FDC_Slope_BrkPt_Dry2.txt'; \n",
    "    fdc_infoALL=pd.read_csv(filepath,sep='\\t',header=0); \n",
    "    fdc_info=fdc_infoALL[fdc_infoALL.gauge==gauge];\n",
    "    \n",
    "    display(fdc_info); print('FDC INFO'); \n",
    "    display(name); print('NAME'); display(OtherAnalysis); print('FLOWS INFO'); display(hydro); print('HYDROLOGY'); \n",
    "    display(clim); print('CLIMATE'); display(geol); print('GEOLOGY'); display(soil); print('SOIL'); \n",
    "    display(topo); print('TOPOGRAPHY'); display(vege); print('VEGETATION');\n",
    "    \n",
    "def returnattributeset(dataset): \n",
    "    \"\"\"returns full dataframe of attributes/signatures\n",
    "    dataset options: \n",
    "      'name','geol','clim','hydro','soil','topo','vege'\n",
    "      'OtherAnalysis','fdc_info' \n",
    "    \"\"\"\n",
    "    folder=home+'camels_attributes_v2.0/'; \n",
    "    if dataset=='name':\n",
    "        atttype='name'; filename= folder+'camels_'+atttype+'.txt'; df= pd.read_csv(filename,sep=';',header=0); \n",
    "    if dataset=='geol':\n",
    "        atttype='geol'; filename= folder+'camels_'+atttype+'.txt'; df= pd.read_csv(filename,sep=';',header=0); \n",
    "    if dataset=='clim':\n",
    "        atttype='clim'; filename= folder+'camels_'+atttype+'.txt'; df= pd.read_csv(filename,sep=';',header=0); \n",
    "    if dataset=='hydro':\n",
    "        atttype='hydro';filename= folder+'camels_'+atttype+'.txt'; df= pd.read_csv(filename,sep=';',header=0); \n",
    "    if dataset=='soil':\n",
    "        atttype='soil'; filename= folder+'camels_'+atttype+'.txt'; df= pd.read_csv(filename,sep=';',header=0); \n",
    "    if dataset=='topo':\n",
    "        atttype='topo'; filename= folder+'camels_'+atttype+'.txt'; df= pd.read_csv(filename,sep=';',header=0); \n",
    "    if dataset=='vege':\n",
    "        atttype='vege'; filename= folder+'camels_'+atttype+'.txt'; df= pd.read_csv(filename,sep=';',header=0); \n",
    "    if dataset=='OtherAnalysis':\n",
    "        filepath=processed_data+'GaugeSummaryV6.txt'; OtherAnalysis= pd.read_csv(filepath,sep='\\t',header=0); df=OtherAnalysis[['Gauge','HUC2','Years','Mean','Std','sd_Qann-QBar','sd_Qmon-Qann','sd_Qday-Qmon','Med','fdc20','fdc80','AREA_(KM^2)']]; \n",
    "    if dataset=='fdc_info':\n",
    "        filepath=processed_data+'FDC_Slope_BrkPt_Dry2.txt'; df=pd.read_csv(filepath,sep='\\t',header=0); \n",
    "    return df\n",
    "\n",
    "def fieldlisting(dataX):\n",
    "    \"\"\"Returns list of numeric fields within each dataset\"\"\"\n",
    "    \n",
    "    if dataX== 'clim':\n",
    "        columns=['p_mean','pet_mean','p_seasonality','frac_snow','aridity','high_prec_freq','high_prec_dur','low_prec_freq','low_prec_dur']\n",
    "\n",
    "    if dataX=='topo':\n",
    "        columns=['elev_mean','slope_mean','area_gages2','area_geospa_fabric']\n",
    "\n",
    "    if dataX=='geol':\n",
    "        columns=['carbonate_rocks_frac','geol_porostiy','geol_permeability']\n",
    "\n",
    "    if dataX=='soil':\n",
    "        columns=['soil_depth_pelletier','soil_depth_statsgo','soil_porosity','soil_conductivity','max_water_content','sand_frac','silt_frac','clay_frac','water_frac','organic_frac','other_frac']\n",
    "\n",
    "    if dataX=='vege':\n",
    "        columns=['frac_forest','lai_max','lai_diff','gvf_max','gvf_diff']\n",
    "\n",
    "    if dataX=='hydro':\n",
    "        columns=['q_mean','runoff_ratio','slope_fdc','baseflow_index','stream_elas','q5','q95','high_q_freq','high_q_dur','low_q_freq','low_q_dur','zero_q_freq','hfd_mean']\n",
    "\n",
    "    if dataX=='fdc_info':\n",
    "        columns=['PctFlow','m_90-10','err_1_abs','err_1b','break','err_2_abs','err_2b','m_1','m_2','err_ratio_abs']\n",
    "\n",
    "    if dataX=='OtherAnalysis':\n",
    "        columns=['Mean','Std','sd_Qann-QBar','sd_Qmon-Qann','sd_Qday-Qmon']\n",
    "    return columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Some Comparison Plots "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def comparisonplot(dataX,columnX,dataY,columnY,dataZ='clim',columnZ='p_seasonality',gauge=[],colors=0,s=10,acceptable=[],linewidths=0.25,show=1,alpha=0.7):\n",
    "    \"\"\"Return color scaled scatterplot comparing 2 or 3 fields\n",
    "    dataX/Y/Z:  'name','geol','clim','hydro','soil','topo','vege','OtherAnalysis','fdc_info' \n",
    "    fieldX/Y/Z: column name from above dataset\n",
    "        Z optional\n",
    "    gauge: Can highlight individual gauge on plot\n",
    "    acceptable: Can narrow to subset of gauges with a list of gauge ID\n",
    "    show: 1 if make a figure as is, 0 if want to modify it\n",
    "    colors: decide color system\n",
    "        0: Grey dots, no colormap\n",
    "        1: Binary of always flows/can run dry\n",
    "        2: Pct Flow\n",
    "        3: Divergent\n",
    "        4: Linear\n",
    "        5: col, shiftedcmap, colorbarlabel= customcolors() ...must be defined prior\"\"\"\n",
    "    subsetX=returnattributeset(dataX)\n",
    "    subsetY=returnattributeset(dataY)\n",
    "    subsetZ=returnattributeset(dataZ)\n",
    "\n",
    "    fdc_infoALL=returnattributeset('fdc_info')\n",
    "    subsetZ_B=fdc_infoALL\n",
    "\n",
    "    if acceptable!=[]:\n",
    "        subsetX=subsetX[subsetX.iloc[:,0].isin(acceptable)]; \n",
    "        subsetY=subsetY[subsetY.iloc[:,0].isin(acceptable)]; \n",
    "        subsetZ=subsetZ[subsetZ.iloc[:,0].isin(acceptable)]; \n",
    "        subsetZ_B=subsetZ_B[subsetZ_B.iloc[:,0].isin(acceptable)]\n",
    "    x=subsetX[columnX]; y=subsetY[columnY]\n",
    "\n",
    "    if colors==1:\n",
    "        col=subsetZ_B['Dry'] #'PctFlow']\n",
    "        shiftedcmap= plt.cm.bwr #plasma_r\n",
    "        colorbarlabel='Red: Runs Dry. Blue: Always flows'\n",
    "    if colors==2:\n",
    "        col=subsetZ_B['PctFlow']\n",
    "        colormap= plt.cm.plasma_r\n",
    "        colorscaledata=col\n",
    "        shiftedcmap=shiftedColorMap(colormap, start=-0.2, midpoint=.96, stop=1, name='shiftedcmap')\n",
    "        colorbarlabel='Percentage of days with flow'\n",
    "    if colors==3:\n",
    "        col=subsetZ[columnZ]\n",
    "        colormap=plt.cm.coolwarm_r\n",
    "        colorscaledata=col\n",
    "        cmapmidpoint=1-max(colorscaledata)/(max(colorscaledata)+abs(min(colorscaledata)))\n",
    "        shiftedcmap=shiftedColorMap(colormap, start=0, midpoint=cmapmidpoint, stop=1, name='shiftedcmap')\n",
    "        colorbarlabel=columnZ\n",
    "    if colors==4:\n",
    "        col=subsetZ[columnZ]\n",
    "        shiftedcmap= plt.cm.viridis_r #plasma_r \n",
    "        colorbarlabel=columnZ\n",
    "    if colors ==5:\n",
    "        col, shiftedcmap, colorbarlabel= customcolors() \n",
    "\n",
    "    fig=plt.figure()\n",
    "\n",
    "    if colors!=0:    \n",
    "        plt.set_cmap(shiftedcmap)\n",
    "        plt.scatter(x,y,c=col,s=s,alpha=alpha,edgecolor='k',linewidths=linewidths)\n",
    "        plt.colorbar(label=colorbarlabel);\n",
    "    if colors==0:    plt.scatter(x,y,s=s,alpha=0.3,facecolors='k')\n",
    "    plt.xlabel(columnX); plt.ylabel(columnY)\n",
    "    if gauge!=[]:    plt.scatter(subsetX[subsetX.iloc[:,0]==gauge][columnX],subsetY[subsetY.iloc[:,0]==gauge][columnY],s=40,alpha=1,facecolors='none',edgecolor='k',linewidths=2)\n",
    "    if show==1:      plt.show()\n",
    "    return fig\n",
    "\n",
    "def subsetID(dataX,columnX,xrange,dataY,columnY,yrange,dataZ='clim',columnZ='p_seasonality',zrange=[],colors=0,showthese=[],plot=1,primaryfilter=[]):\n",
    "    \"\"\"Return color scaled scatterplot comparing 2 or 3 fields\n",
    "    dataX/Y/Z:  'name','geol','clim','hydro','soil','topo','vege','OtherAnalysis','fdc_info' \n",
    "    fieldX/Y/Z: column name from above dataset\n",
    "        Z optional\n",
    "    x/y/zrange: bracketed range of values for output to be within\n",
    "    show: 1 if make a figure as is, 0 if want to modify it\n",
    "    primaryfilter: optional, list of existing gauges that this should create a subset of\n",
    "    colors: decide color system\n",
    "        0/1/2: Grey dots, no colormap\n",
    "        3: Divergent\n",
    "        4: Linear\n",
    "        5: col, shiftedcmap, colorbarlabel= customcolors() ...must be defined prior\"\"\"\n",
    "\n",
    "    acceptable=gaugefilter(dataX,columnX,xrange) & gaugefilter(dataY,columnY,yrange)\n",
    "    if zrange!=[]: acceptable = acceptable & gaugefilter(dataZ,columnZ,zrange)\n",
    "\n",
    "    if primaryfilter !=[]:\n",
    "        acceptable = acceptable & set(primaryfilter)\n",
    "        \n",
    "    dfX=returnattributeset(dataX)\n",
    "    dfY=returnattributeset(dataY)\n",
    "    dfZ=returnattributeset(dataZ)\n",
    "    xgood=dfX[dfX.iloc[:,0].isin(acceptable)]\n",
    "    ygood=dfY[dfY.iloc[:,0].isin(acceptable)]\n",
    "    zgood=dfZ[dfZ.iloc[:,0].isin(acceptable)]\n",
    "\n",
    "    if colors==1:    colors=0\n",
    "    if colors==2:    colors=0\n",
    "    if colors==3:\n",
    "        col=zgood[columnZ]\n",
    "        colormap=plt.cm.coolwarm_r\n",
    "        colorscaledata=col\n",
    "        cmapmidpoint=1-max(colorscaledata)/(max(colorscaledata)+abs(min(colorscaledata)))\n",
    "        shiftedcmap=shiftedColorMap(colormap, start=0, midpoint=cmapmidpoint, stop=1, name='shiftedcmap')\n",
    "        colorbarlabel=columnZ\n",
    "    if colors==4:\n",
    "        col=zgood[columnZ]\n",
    "        shiftedcmap= plt.cm.viridis_r\n",
    "        colorbarlabel=columnZ\n",
    "    if colors ==5:\n",
    "        col, shiftedcmap, colorbarlabel= customcolors() \n",
    "\n",
    "    fig=plt.figure()\n",
    "    if colors!=0: \n",
    "        plt.scatter(xgood[columnX],ygood[columnY],c=col,s=20,alpha=0.6,edgecolor='k',linewidths=0.5)\n",
    "        plt.colorbar(label=colorbarlabel); \n",
    "    if colors==0:\n",
    "        plt.scatter(xgood[columnX],ygood[columnY],s=20,alpha=0.6,facecolors='b',edgecolor='k',linewidths=0.5)\n",
    "    plt.xlabel(columnX); plt.ylabel(columnY)\n",
    "    if plot==1:  plt.show()\n",
    "    if 'x' in showthese:    display(xgood)\n",
    "    if 'y' in showthese:    display(ygood)\n",
    "    if 'z' in showthese:    display(zgood)\n",
    "    return fig\n",
    "\n",
    "def FDCstack(subset,ylims=[0.001,500],subsetname='Subset',alpha=0.2,color='k',show=1):\n",
    "    \"\"\"Returns overlayed scaled FDCs for a list of gauges\n",
    "    Runs fairly slowly\n",
    "    Dependent on loadflow(gauge) and FDC(gauge)\"\"\"\n",
    "    \n",
    "    subset=list(subset)\n",
    "    ngauges=np.size(subset)\n",
    "    fig=plt.figure()\n",
    "\n",
    "    for gauge in subset:\n",
    "        data = loadflow(gauge)\n",
    "        fdc = FDC(gauge)\n",
    "\n",
    "        # Remove any years missing a lot of data\n",
    "        numdays=329 #minimum number of days\n",
    "        fdc_data=data\n",
    "        fdc_data=fdc_data[fdc_data[4] != -999.0] #remove nulls\n",
    "        yr1=min(fdc_data[1].values)\n",
    "        yrEnd=max(fdc_data[1].values)\n",
    "        for year in range(yr1,yrEnd+1):\n",
    "            if np.sum(fdc_data[1]==year)<numdays:\n",
    "                fdc_data=fdc_data[fdc_data[1] != year]\n",
    "\n",
    "        QBar=fdc_data.mean()[4]\n",
    "\n",
    "        plt.semilogy(fdc['Percent Exceed'],fdc['Flow']/QBar,color=color,alpha=alpha)\n",
    "\n",
    "    axes = plt.gca()\n",
    "    axes.set_xlim([-3,103])\n",
    "    axes.set_ylim(ylims)\n",
    "\n",
    "    plt.ylabel('Daily Average Flow / Period of Record Mean')\n",
    "    plt.xlabel('Percentage of Time Flow Exceeded') \n",
    "    plt.title('Scaled FDCs for '+str(ngauges)+' Gauges in '+subsetname)\n",
    "    if show==1: plt.show()\n",
    "    return fig\n",
    "\n",
    "def HydrographStack(subset,ylims=[0.001,10],subsetname='Subset',alpha=0.4,color='k',show=1):\n",
    "    \"\"\"Returns overlayed scaled typical (mean) hydrographs for a list of gauges\n",
    "    Runs fast, but requires MedAnnHydrograph.txt\n",
    "    Dependent on loadflow(gauge) and FDC(gauge)\"\"\"\n",
    "    \n",
    "    filename=processed_data+'MedAnnHydrograph.txt'\n",
    "    df = pd.read_csv(filename,sep='\\t',header=0)\n",
    "    \n",
    "    subset=list(subset)\n",
    "    ngauges=np.size(subset)\n",
    "    if show==1:\n",
    "        fig, ax1 = plt.subplots()\n",
    "   \n",
    "    for gauge in subset:\n",
    "        ax1.semilogy(df[str(gauge)],color=color,alpha=alpha)\n",
    "\n",
    "    #plt.title('Typical Hydrographs for '+str(ngauges)+' Gauges in '+subsetname)\n",
    "    plt.title(str(ngauges)+' Gauges in '+subsetname)\n",
    "    ax1.set_ylabel('Median Daily Flow/Period Mean Flow')\n",
    "    axes = plt.gca()\n",
    "    axes.set_ylim(ylims)\n",
    "    xticklabels=['Jan','Feb','Mar','Apr','May','Jun','Jul','Aug','Sep','Oct','Nov','Dec']\n",
    "    ax1.set_xticks([15,45,74,105,135,166,196,227,258,288,319,349],minor=False)\n",
    "    ax1.set_xticks([0,31,59,90,120,151,181,212,243,273,304,334,365],minor=True)\n",
    "    ax1.set_xticklabels(xticklabels)\n",
    "    ax1.tick_params(axis='x',which='major',bottom=False,top=False,labelbottom=True)\n",
    "    ax1.tick_params(axis='x',which='minor',bottom=True,top=False,labelbottom=False,width=-.5,length=18)\n",
    "    if show==1: plt.show()\n",
    "    return fig\n",
    "\n",
    "def HydrographStackSLOW(subset,ylims=[0.001,10],subsetname='Subset'):\n",
    "    \"\"\"Returns overlayed scaled typical (mean) hydrographs for a list of gauges\n",
    "    Runs very slowly\n",
    "    Dependent on loadflow(gauge) and FDC(gauge)\"\"\"\n",
    "    \n",
    "    subset=list(subset)\n",
    "    ngauges=np.size(subset)\n",
    "    fig, ax1 = plt.subplots()\n",
    "\n",
    "    for gauge in subset:\n",
    "        data = loadflow(gauge)\n",
    "        data=data.replace(-999.0,np.nan)\n",
    "  \n",
    "        QBar=data.mean()[4]\n",
    "        \n",
    "        yrsum= pd.DataFrame(columns=['Month','Day','Median','Min','Max'])\n",
    "        n=0\n",
    "        for month in range(1,13,1):\n",
    "            if month in [9,4,6,11]: #30 \n",
    "                for day in range(1,31):\n",
    "                    yrsum.loc[n,'Month']=month\n",
    "                    yrsum.loc[n,'Day']=day\n",
    "                    yrsum.loc[n,'Median']=data[(data[3]==day) & (data[2]==month)][4].median()\n",
    "                    n=n+1\n",
    "            if month in [1,3,5,7,8,10,12]: #31\n",
    "                for day in range(1,32):\n",
    "                    yrsum.loc[n,'Month']=month\n",
    "                    yrsum.loc[n,'Day']=day\n",
    "                    yrsum.loc[n,'Median']=data[(data[3]==day) & (data[2]==month)][4].median()\n",
    "                    n=n+1\n",
    "            if month == 2: #stupid february\n",
    "                for day in range(1,29):\n",
    "                    yrsum.loc[n,'Month']=month\n",
    "                    yrsum.loc[n,'Day']=day\n",
    "                    yrsum.loc[n,'Median']=data[(data[3]==day) & (data[2]==month)][4].median()\n",
    "                    n=n+1\n",
    "        ax1.semilogy(yrsum['Median']/QBar,'k-',alpha=0.4)\n",
    "        \n",
    "    plt.title('Typical Hydrographs for '+str(ngauges)+' Gauges in '+subsetname)\n",
    "    ax1.set_ylabel('Median Daily Flow/Period Mean Flow')\n",
    "    axes = plt.gca()\n",
    "    axes.set_ylim(ylims)\n",
    "    xticklabels=['Jan','Feb','Mar','Apr','May','Jun','Jul','Aug','Sep','Oct','Nov','Dec']\n",
    "    ax1.set_xticks([15,45,74,105,135,166,196,227,258,288,319,349],minor=False)\n",
    "    ax1.set_xticks([0,31,59,90,120,151,181,212,243,273,304,334,365],minor=True)\n",
    "    ax1.set_xticklabels(xticklabels)\n",
    "    ax1.tick_params(axis='x',which='major',bottom=False,top=False,labelbottom=True)\n",
    "    ax1.tick_params(axis='x',which='minor',bottom=True,top=False,labelbottom=False,width=-.5,length=18)\n",
    "    plt.show()\n",
    "    return fig"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Forcing Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loadforcing(gauge,dataset='daymet'):\n",
    "    \"\"\"returns forcing data for given gauge from either 'daymet','maurer', or 'nldas'\"\"\"\n",
    "    \n",
    "    forcingfolder = home+'basin_timeseries_v1p2_metForcing_obsFlow/basin_dataset_public_v1p2/basin_mean_forcing/'+dataset+'/'\n",
    "    gaugeinfo = home + 'basin_timeseries_v1p2_metForcing_obsFlow/basin_dataset_public_v1p2/basin_metadata/gauge_information.txt'\n",
    "\n",
    "    gauges = pd.read_csv(gaugeinfo,sep='\\t',header=0)  #had to adjust headers to line up right\n",
    "    huc_id=gauges[gauges.GAGE_ID==gauge]['HUC_02'].values[0]\n",
    "\n",
    "    GaugeInfo=gauges[gauges.GAGE_ID==gauge]\n",
    "\n",
    "    if huc_id <10:\n",
    "        nhuc = '0'+str(huc_id)\n",
    "    else:\n",
    "        nhuc = str(huc_id)\n",
    "\n",
    "    forcings = forcingfolder+nhuc+'/'\n",
    "\n",
    "    if dataset == 'daymet':\n",
    "        label = 'cida'\n",
    "    else:\n",
    "        label=dataset\n",
    "\n",
    "    if gauge < 10000000:\n",
    "        data=forcings+'0'+str(gauge)+'_lump_'+label+'_forcing_leap.txt'\n",
    "    else:\n",
    "        data=forcings+str(gauge)+'_lump_'+label+'_forcing_leap.txt'\n",
    "\n",
    "    data=pd.read_csv(data,sep='\\s+',header=3)\n",
    "    return data\n",
    "\n",
    "def ForcingMinMedMax(gauge,columnname,dataset='daymet'):\n",
    "    \"\"\"return min/med/max plot for any of the forcing data over the years\n",
    "    dataset 'daymet','maurer', or 'nldas'\n",
    "    Dependent on loadforcing(gauge,dataset)\"\"\"\n",
    "\n",
    "    data=loadforcing(gauge,dataset)\n",
    "    data=data.replace(-999.0,np.nan)\n",
    "\n",
    "    yrsum= pd.DataFrame(columns=['Month','Day','Median','Min','Max'])\n",
    "    n=0\n",
    "    for month in range(1,13,1):\n",
    "        if month in [9,4,6,11]: #30 \n",
    "            for day in range(1,31):\n",
    "                yrsum.loc[n,'Month']=month\n",
    "                yrsum.loc[n,'Day']=day\n",
    "                yrsum.loc[n,'Median']=data[(data['Day']==day) & (data['Mnth']==month)][columnname].median()\n",
    "                yrsum.loc[n,'Min']=data[(data['Day']==day) & (data['Mnth']==month)][columnname].min()\n",
    "                yrsum.loc[n,'Max']=data[(data['Day']==day) & (data['Mnth']==month)][columnname].max()\n",
    "                n=n+1\n",
    "        if month in [1,3,5,7,8,10,12]: #31\n",
    "            for day in range(1,32):\n",
    "                yrsum.loc[n,'Month']=month\n",
    "                yrsum.loc[n,'Day']=day\n",
    "                yrsum.loc[n,'Median']=data[(data['Day']==day) & (data['Mnth']==month)][columnname].median()\n",
    "                yrsum.loc[n,'Min']=data[(data['Day']==day) & (data['Mnth']==month)][columnname].min()\n",
    "                yrsum.loc[n,'Max']=data[(data['Day']==day) & (data['Mnth']==month)][columnname].max()\n",
    "                n=n+1\n",
    "        if month == 2: #stupid february\n",
    "            for day in range(1,29):\n",
    "                yrsum.loc[n,'Month']=month\n",
    "                yrsum.loc[n,'Day']=day\n",
    "                yrsum.loc[n,'Median']=data[(data['Day']==day) & (data['Mnth']==month)][columnname].median()\n",
    "                yrsum.loc[n,'Min']=data[(data['Day']==day) & (data['Mnth']==month)][columnname].min()\n",
    "                yrsum.loc[n,'Max']=data[(data['Day']==day) & (data['Mnth']==month)][columnname].max()\n",
    "                n=n+1\n",
    "\n",
    "    fig, ax1 = plt.subplots()\n",
    "\n",
    "    ax1.plot(yrsum['Max'],'b-',label='Max')\n",
    "    ax1.plot(yrsum['Median'],'k-',label='Median')\n",
    "    ax1.plot(yrsum['Min'],'r-',label='Min')\n",
    "    plt.legend(bbox_to_anchor=(1.02, 1), loc=2, borderaxespad=0.)\n",
    "    plt.title(columnname+' Annual Variations at Gauge '+str(gauge))\n",
    "    ax1.set_ylabel(columnname)\n",
    "    xticklabels=['Jan','Feb','Mar','Apr','May','Jun','Jul','Aug','Sep','Oct','Nov','Dec']\n",
    "    ax1.set_xticks([15,45,74,105,135,166,196,227,258,288,319,349],minor=False)\n",
    "    ax1.set_xticks([0,31,59,90,120,151,181,212,243,273,304,334,365],minor=True)\n",
    "    ax1.set_xticklabels(xticklabels)\n",
    "    ax1.tick_params(axis='x',which='major',bottom=False,top=False,labelbottom=True)\n",
    "    ax1.tick_params(axis='x',which='minor',bottom=True,top=False,labelbottom=False,width=-.5,length=18)\n",
    "    plt.show()\n",
    "    return fig\n",
    "\n",
    "def RasterPrecip(gauge,dataset='daymet'):\n",
    "    \"\"\"makes plot similar to raster hydrograph but of daily precipitation \n",
    "    dataset 'daymet','maurer', or 'nldas'   \n",
    "    Dependent on loadforcing(gauge,dataset)\"\"\"\n",
    "\n",
    "    columnname='prcp(mm/day)'\n",
    "    \n",
    "    data=loadforcing(gauge,dataset)\n",
    "    \n",
    "    data=data.replace(-999.0,np.nan)\n",
    "    \n",
    "    Years=data['Year'].unique()\n",
    "    NYears=np.size(Years)\n",
    "    RastData = np.empty([NYears,365])\n",
    "    StartYear=Years[0]\n",
    "    EndYear=Years[NYears-1]\n",
    "\n",
    "    for nyear in range(0,NYears):\n",
    "        yrdata=data[data['Year']==Years[nyear]][columnname].values\n",
    "        if np.size(yrdata)==366: #leap years are a pain, let's just delete feb 29 from all years \n",
    "            yrdata=np.delete(yrdata,59)\n",
    "        RastData[nyear,:]=yrdata\n",
    "\n",
    "    RHscaled=RastData #np.log10(RastData+1) #making 0 flow days not break the log scale\n",
    "\n",
    "    fig=plt.figure()\n",
    "    shiftedcmap= plt.cm.cool\n",
    "    shiftedcmap.set_under('white') \n",
    "\n",
    "    imgplot=plt.imshow(RHscaled,interpolation='nearest', aspect='auto',vmin=0.001) #,extent=[0,25,0,20])\n",
    "    imgplot.set_cmap(shiftedcmap)\n",
    "    plt.title('Gauge '+str(gauge)+', '+str(StartYear)+'-'+str(EndYear))\n",
    "    plt.colorbar(label=columnname)\n",
    "    plt.tick_params(\n",
    "        axis='x',          # changes apply to the x-axis\n",
    "        which='major',      # both major and minor ticks are affected\n",
    "        bottom=False,      # ticks along the bottom edge are off\n",
    "        top=False,         # ticks along the top edge are off\n",
    "        labelbottom=True) # labels along the bottom edge are off\n",
    "\n",
    "    xticklabels=['Jan','Feb','Mar','Apr','May','Jun','Jul','Aug','Sep','Oct','Nov','Dec']\n",
    "    plt.xticks([15,45,74,105,135,166,196,227,258,288,319,349], xticklabels)\n",
    "    labelnum=range(0,NYears,2)\n",
    "    yticklabels=np.ones(np.size(labelnum),dtype=np.int16)\n",
    "    for n in range(0,np.size(labelnum)):\n",
    "        yticklabels[n]=StartYear+labelnum[n]\n",
    "    plt.yticks(range(0,NYears,2), yticklabels)\n",
    "    plt.show()\n",
    "    return fig\n",
    "\n",
    "def RasterTemps(gauge,maxmin,dataset='daymet'):\n",
    "    \"\"\"makes plot similar to raster hydrograph but of daily temperature max or min records \n",
    "    maxmin either = 'max' or 'min'\n",
    "    dataset 'daymet','maurer', or 'nldas'\n",
    "    Dependent on loadforcing(gauge,dataset)\"\"\"\n",
    "    \n",
    "    if maxmin=='max':\n",
    "        columnname='tmax(C)' #'prcp(mm/day)'\n",
    "    if maxmin=='min': \n",
    "        columnname='tmin(C)'\n",
    "        \n",
    "    data=loadforcing(gauge,dataset)\n",
    "\n",
    "    data=data.replace(-999.0,np.nan)\n",
    "\n",
    "    Years=data['Year'].unique()\n",
    "    NYears=np.size(Years)\n",
    "    RastData = np.empty([NYears,365])\n",
    "    StartYear=Years[0]\n",
    "    EndYear=Years[NYears-1]\n",
    "\n",
    "    for nyear in range(0,NYears):\n",
    "        yrdata=data[data['Year']==Years[nyear]][columnname].values\n",
    "        if np.size(yrdata)==366: #leap years are a pain, let's just delete feb 29 from all years \n",
    "            yrdata=np.delete(yrdata,59)\n",
    "        RastData[nyear,:]=yrdata\n",
    "\n",
    "    RHscaled=RastData #np.log10(RastData+0.001) #making 0 flow days not break the log scale\n",
    "\n",
    "    fig=plt.figure()\n",
    "    colormap=plt.cm.bwr #coolwarm\n",
    "    rangetemps=[np.max(RastData), np.min(RastData)]\n",
    "    colorscaledata=rangetemps\n",
    "    cmapmidpoint=1-max(colorscaledata)/(max(colorscaledata)+abs(min(colorscaledata)))\n",
    "    shiftedcmap=shiftedColorMap(colormap, start=0, midpoint=cmapmidpoint, stop=1, name='shiftedcmap')\n",
    "\n",
    "\n",
    "    imgplot=plt.imshow(RHscaled,interpolation='nearest', aspect='auto') #,extent=[0,25,0,20])\n",
    "    imgplot.set_cmap(shiftedcmap)\n",
    "    plt.title('Gauge '+str(gauge)+', '+str(StartYear)+'-'+str(EndYear))\n",
    "    plt.colorbar(label=columnname)\n",
    "    plt.tick_params(\n",
    "        axis='x',          # changes apply to the x-axis\n",
    "        which='major',      # both major and minor ticks are affected\n",
    "        bottom=False,      # ticks along the bottom edge are off\n",
    "        top=False,         # ticks along the top edge are off\n",
    "        labelbottom=True) # labels along the bottom edge are off\n",
    "\n",
    "    xticklabels=['Jan','Feb','Mar','Apr','May','Jun','Jul','Aug','Sep','Oct','Nov','Dec']\n",
    "    plt.xticks([15,45,74,105,135,166,196,227,258,288,319,349], xticklabels)\n",
    "    labelnum=range(0,NYears,2)\n",
    "    yticklabels=np.ones(np.size(labelnum),dtype=np.int16)\n",
    "    for n in range(0,np.size(labelnum)):\n",
    "        yticklabels[n]=StartYear+labelnum[n]\n",
    "    plt.yticks(range(0,NYears,2), yticklabels)\n",
    "    plt.show()\n",
    "    return fig\n",
    "\n",
    "def RollingRasterPrecip(gauge,dataset='daymet',window=30, scalemax=[]):\n",
    "    \"\"\"Creates a raster plot of sum of n days previous precipitation for each day.\n",
    "    Start dates without full window blacked out\n",
    "    White if full window of no precipitation\n",
    "    Dependent on loadforcing(gauge,dataset)\"\"\"\n",
    "    \n",
    "    data = loadforcing(gauge,dataset)\n",
    "    \n",
    "    columnname='RollingPrcp(mm/mo)'\n",
    "    data[columnname]=data['prcp(mm/day)'].rolling(window).sum()\n",
    "\n",
    "    Years=data['Year'].unique()\n",
    "    NYears=np.size(Years)\n",
    "    RastData = np.empty([NYears,365])\n",
    "    StartYear=Years[0]\n",
    "    EndYear=Years[NYears-1]\n",
    "\n",
    "    for nyear in range(0,NYears):\n",
    "        yrdata=data[data['Year']==Years[nyear]][columnname].values\n",
    "        if np.size(yrdata)==366: #leap years are a pain, let's just delete feb 29 from all years \n",
    "            yrdata=np.delete(yrdata,59)\n",
    "        RastData[nyear,:]=yrdata\n",
    "\n",
    "    RHscaled=RastData #np.log10(RastData+1) #making 0 flow days not break the log scale\n",
    "\n",
    "    fig=plt.figure()\n",
    "    shiftedcmap= plt.cm.cool\n",
    "    shiftedcmap.set_under('white') \n",
    "    shiftedcmap.set_bad('black') \n",
    "\n",
    "\n",
    "    if scalemax==[]: imgplot=plt.imshow(RHscaled,interpolation='nearest', aspect='auto',vmin=0.001) #,extent=[0,25,0,20])\n",
    "    if scalemax!=[]: imgplot=plt.imshow(RHscaled,interpolation='nearest', aspect='auto',vmin=0.001,vmax=scalemax) #,extent=[0,25,0,20])\n",
    "\n",
    "    imgplot.set_cmap(shiftedcmap)\n",
    "    plt.title('Gauge '+str(gauge)+', '+str(StartYear)+'-'+str(EndYear))\n",
    "    plt.colorbar(label=columnname)\n",
    "    plt.tick_params(\n",
    "        axis='x',          # changes apply to the x-axis\n",
    "        which='major',      # both major and minor ticks are affected\n",
    "        bottom=False,      # ticks along the bottom edge are off\n",
    "        top=False,         # ticks along the top edge are off\n",
    "        labelbottom=True) # labels along the bottom edge are off\n",
    "\n",
    "    xticklabels=['Jan','Feb','Mar','Apr','May','Jun','Jul','Aug','Sep','Oct','Nov','Dec']\n",
    "    plt.xticks([15,45,74,105,135,166,196,227,258,288,319,349], xticklabels)\n",
    "    labelnum=range(0,NYears,2)\n",
    "    yticklabels=np.ones(np.size(labelnum),dtype=np.int16)\n",
    "    for n in range(0,np.size(labelnum)):\n",
    "        yticklabels[n]=StartYear+labelnum[n]\n",
    "    plt.yticks(range(0,NYears,2), yticklabels)\n",
    "    plt.show()\n",
    "    return fig\n",
    "\n",
    "def RollingTypicalPrecip(gauge,dataset='daymet',window=30):\n",
    "    \"\"\"Gives min/med/max for precipitation over year given a window length\n",
    "    Dependent on loadforcing(gauge,dataset)\"\"\"\n",
    "\n",
    "    data = loadforcing(gauge,dataset)\n",
    "    \n",
    "    columnname='RollingPrcp(mm/mo)'\n",
    "    data[columnname]=data['prcp(mm/day)'].rolling(window).sum()\n",
    "\n",
    "    \n",
    "    Years=data['Year'].unique()\n",
    "    NYears=np.size(Years)\n",
    "    RastData = np.empty([NYears,365])\n",
    "    StartYear=Years[0]\n",
    "    EndYear=Years[NYears-1]\n",
    "\n",
    "    for nyear in range(0,NYears):\n",
    "        yrdata=data[data['Year']==Years[nyear]][columnname].values\n",
    "        if np.size(yrdata)==366: #leap years are a pain, let's just delete feb 29 from all years \n",
    "            yrdata=np.delete(yrdata,59)\n",
    "        RastData[nyear,:]=yrdata\n",
    "\n",
    "    yrsum= pd.DataFrame(columns=['Month','Day','Median','Min','Max'])\n",
    "    n=0\n",
    "    for month in range(1,13,1):\n",
    "        if month in [9,4,6,11]: #30 \n",
    "            for day in range(1,31):\n",
    "                yrsum.loc[n,'Month']=month\n",
    "                yrsum.loc[n,'Day']=day\n",
    "                yrsum.loc[n,'Median']=data[(data['Day']==day) & (data['Mnth']==month)][columnname].median()\n",
    "                yrsum.loc[n,'Min']=data[(data['Day']==day) & (data['Mnth']==month)][columnname].min()\n",
    "                yrsum.loc[n,'Max']=data[(data['Day']==day) & (data['Mnth']==month)][columnname].max()\n",
    "                n=n+1\n",
    "        if month in [1,3,5,7,8,10,12]: #31\n",
    "            for day in range(1,32):\n",
    "                yrsum.loc[n,'Month']=month\n",
    "                yrsum.loc[n,'Day']=day\n",
    "                yrsum.loc[n,'Median']=data[(data['Day']==day) & (data['Mnth']==month)][columnname].median()\n",
    "                yrsum.loc[n,'Min']=data[(data['Day']==day) & (data['Mnth']==month)][columnname].min()\n",
    "                yrsum.loc[n,'Max']=data[(data['Day']==day) & (data['Mnth']==month)][columnname].max()\n",
    "                n=n+1\n",
    "        if month == 2: #stupid february\n",
    "            for day in range(1,29):\n",
    "                yrsum.loc[n,'Month']=month\n",
    "                yrsum.loc[n,'Day']=day\n",
    "                yrsum.loc[n,'Median']=data[(data['Day']==day) & (data['Mnth']==month)][columnname].median()\n",
    "                yrsum.loc[n,'Min']=data[(data['Day']==day) & (data['Mnth']==month)][columnname].min()\n",
    "                yrsum.loc[n,'Max']=data[(data['Day']==day) & (data['Mnth']==month)][columnname].max()\n",
    "                n=n+1\n",
    "\n",
    "    fig, ax1 = plt.subplots()\n",
    "    ax1.plot(yrsum['Max'],'b-',label='Max')\n",
    "    ax1.plot(yrsum['Median'],'k-',label='Median')\n",
    "    ax1.plot(yrsum['Min'],'r-',label='Min')\n",
    "    plt.legend(bbox_to_anchor=(1.02, 1), loc=2, borderaxespad=0.)\n",
    "    plt.title(columnname+' Annual Variations at '+str(gauge))\n",
    "    ax1.set_ylabel(columnname)\n",
    "    xticklabels=['Jan','Feb','Mar','Apr','May','Jun','Jul','Aug','Sep','Oct','Nov','Dec']\n",
    "    ax1.set_xticks([15,45,74,105,135,166,196,227,258,288,319,349],minor=False)\n",
    "    ax1.set_xticks([0,31,59,90,120,151,181,212,243,273,304,334,365],minor=True)\n",
    "    ax1.set_xticklabels(xticklabels)\n",
    "    ax1.tick_params(axis='x',which='major',bottom=False,top=False,labelbottom=True)\n",
    "    ax1.tick_params(axis='x',which='minor',bottom=True,top=False,labelbottom=False,width=-.5,length=18)\n",
    "    plt.show()\n",
    "    return fig\n",
    "\n",
    "def RollingPrcp_select(gauge,selected_years,window=30,dataset='daymet'):\n",
    "    \"\"\"Plots rolling average precip for selected years over min/med/max for the period\n",
    "    Dependent on loadforcing(gauge,dataset)\"\"\"\n",
    "    \n",
    "    data = loadforcing(gauge,dataset)\n",
    "\n",
    "    columnname='RollingPrcp(mm/mo)'\n",
    "    data[columnname]=data['prcp(mm/day)'].rolling(window).sum()\n",
    "\n",
    "\n",
    "    yrsum= pd.DataFrame(columns=['Month','Day','Median','Min','Max'])\n",
    "    n=0\n",
    "    for month in range(1,13,1):\n",
    "        if month in [9,4,6,11]: #30 \n",
    "            for day in range(1,31):\n",
    "                yrsum.loc[n,'Month']=month\n",
    "                yrsum.loc[n,'Day']=day\n",
    "                yrsum.loc[n,'Median']=data[(data['Day']==day) & (data['Mnth']==month)][columnname].median()\n",
    "                yrsum.loc[n,'Min']=data[(data['Day']==day) & (data['Mnth']==month)][columnname].min()\n",
    "                yrsum.loc[n,'Max']=data[(data['Day']==day) & (data['Mnth']==month)][columnname].max()\n",
    "                n=n+1\n",
    "        if month in [1,3,5,7,8,10,12]: #31\n",
    "            for day in range(1,32):\n",
    "                yrsum.loc[n,'Month']=month\n",
    "                yrsum.loc[n,'Day']=day\n",
    "                yrsum.loc[n,'Median']=data[(data['Day']==day) & (data['Mnth']==month)][columnname].median()\n",
    "                yrsum.loc[n,'Min']=data[(data['Day']==day) & (data['Mnth']==month)][columnname].min()\n",
    "                yrsum.loc[n,'Max']=data[(data['Day']==day) & (data['Mnth']==month)][columnname].max()\n",
    "                n=n+1\n",
    "        if month == 2: #stupid february\n",
    "            for day in range(1,29):\n",
    "                yrsum.loc[n,'Month']=month\n",
    "                yrsum.loc[n,'Day']=day\n",
    "                yrsum.loc[n,'Median']=data[(data['Day']==day) & (data['Mnth']==month)][columnname].median()\n",
    "                yrsum.loc[n,'Min']=data[(data['Day']==day) & (data['Mnth']==month)][columnname].min()\n",
    "                yrsum.loc[n,'Max']=data[(data['Day']==day) & (data['Mnth']==month)][columnname].max()\n",
    "                n=n+1\n",
    "\n",
    "    fig, ax1 = plt.subplots()\n",
    "    ax1.plot(yrsum['Max'],'b-',label='Max',alpha=0.5)\n",
    "    ax1.plot(yrsum['Median'],'k-',label='Median',alpha=0.5)\n",
    "    ax1.plot(yrsum['Min'],'r-',label='Min',alpha=0.5)\n",
    "\n",
    "    for year in selected_years:\n",
    "        tempdata=data[data.Year == year]\n",
    "        ax1.plot(range(0,365),tempdata[columnname],'-',label=str(year))\n",
    "\n",
    "    plt.legend(bbox_to_anchor=(1.02, 1), loc=2, borderaxespad=0.)\n",
    "    plt.title(columnname+' Annual Variations at '+str(gauge))\n",
    "    ax1.set_ylabel(columnname)\n",
    "    xticklabels=['Jan','Feb','Mar','Apr','May','Jun','Jul','Aug','Sep','Oct','Nov','Dec']\n",
    "    ax1.set_xticks([15,45,74,105,135,166,196,227,258,288,319,349],minor=False)\n",
    "    ax1.set_xticks([0,31,59,90,120,151,181,212,243,273,304,334,365],minor=True)\n",
    "    ax1.set_xticklabels(xticklabels)\n",
    "    ax1.tick_params(axis='x',which='major',bottom=False,top=False,labelbottom=True)\n",
    "    ax1.tick_params(axis='x',which='minor',bottom=True,top=False,labelbottom=False,width=-.5,length=18)\n",
    "    plt.show()\n",
    "    return fig\n",
    "\n",
    "def TypicalTemps(gauge,dataset='daymet'):\n",
    "    \"\"\"makes plot similar to Typical Year hydrograph but of daily temperature min/med/max records \n",
    "    dataset 'daymet','maurer', or 'nldas'\n",
    "    Dependent on loadforcing(gauge,dataset)\"\"\"\n",
    "\n",
    "    data=loadforcing(gauge,dataset)\n",
    "    data=data.replace(-999.0,np.nan)\n",
    "\n",
    "    columnname='tmax(C)'\n",
    "    yrsumMAX= pd.DataFrame(columns=['Month','Day','Median','Min','Max'])\n",
    "    n=0\n",
    "    for month in range(1,13,1):\n",
    "        if month in [9,4,6,11]: #30 \n",
    "            for day in range(1,31):\n",
    "                yrsumMAX.loc[n,'Month']=month\n",
    "                yrsumMAX.loc[n,'Day']=day\n",
    "                yrsumMAX.loc[n,'Median']=data[(data['Day']==day) & (data['Mnth']==month)][columnname].median()\n",
    "                yrsumMAX.loc[n,'Min']=data[(data['Day']==day) & (data['Mnth']==month)][columnname].min()\n",
    "                yrsumMAX.loc[n,'Max']=data[(data['Day']==day) & (data['Mnth']==month)][columnname].max()\n",
    "                n=n+1\n",
    "        if month in [1,3,5,7,8,10,12]: #31\n",
    "            for day in range(1,32):\n",
    "                yrsumMAX.loc[n,'Month']=month\n",
    "                yrsumMAX.loc[n,'Day']=day\n",
    "                yrsumMAX.loc[n,'Median']=data[(data['Day']==day) & (data['Mnth']==month)][columnname].median()\n",
    "                yrsumMAX.loc[n,'Min']=data[(data['Day']==day) & (data['Mnth']==month)][columnname].min()\n",
    "                yrsumMAX.loc[n,'Max']=data[(data['Day']==day) & (data['Mnth']==month)][columnname].max()\n",
    "                n=n+1\n",
    "        if month == 2: #stupid february\n",
    "            for day in range(1,29):\n",
    "                yrsumMAX.loc[n,'Month']=month\n",
    "                yrsumMAX.loc[n,'Day']=day\n",
    "                yrsumMAX.loc[n,'Median']=data[(data['Day']==day) & (data['Mnth']==month)][columnname].median()\n",
    "                yrsumMAX.loc[n,'Min']=data[(data['Day']==day) & (data['Mnth']==month)][columnname].min()\n",
    "                yrsumMAX.loc[n,'Max']=data[(data['Day']==day) & (data['Mnth']==month)][columnname].max()\n",
    "                n=n+1\n",
    "\n",
    "    columnname='tmin(C)'\n",
    "    yrsumMIN= pd.DataFrame(columns=['Month','Day','Median','Min','Max'])\n",
    "    n=0\n",
    "    for month in range(1,13,1):\n",
    "        if month in [9,4,6,11]: #30 \n",
    "            for day in range(1,31):\n",
    "                yrsumMIN.loc[n,'Month']=month\n",
    "                yrsumMIN.loc[n,'Day']=day\n",
    "                yrsumMIN.loc[n,'Median']=data[(data['Day']==day) & (data['Mnth']==month)][columnname].median()\n",
    "                yrsumMIN.loc[n,'Min']=data[(data['Day']==day) & (data['Mnth']==month)][columnname].min()\n",
    "                yrsumMIN.loc[n,'Max']=data[(data['Day']==day) & (data['Mnth']==month)][columnname].max()\n",
    "                n=n+1\n",
    "        if month in [1,3,5,7,8,10,12]: #31\n",
    "            for day in range(1,32):\n",
    "                yrsumMIN.loc[n,'Month']=month\n",
    "                yrsumMIN.loc[n,'Day']=day\n",
    "                yrsumMIN.loc[n,'Median']=data[(data['Day']==day) & (data['Mnth']==month)][columnname].median()\n",
    "                yrsumMIN.loc[n,'Min']=data[(data['Day']==day) & (data['Mnth']==month)][columnname].min()\n",
    "                yrsumMIN.loc[n,'Max']=data[(data['Day']==day) & (data['Mnth']==month)][columnname].max()\n",
    "                n=n+1\n",
    "        if month == 2: #stupid february\n",
    "            for day in range(1,29):\n",
    "                yrsumMIN.loc[n,'Month']=month\n",
    "                yrsumMIN.loc[n,'Day']=day\n",
    "                yrsumMIN.loc[n,'Median']=data[(data['Day']==day) & (data['Mnth']==month)][columnname].median()\n",
    "                yrsumMIN.loc[n,'Min']=data[(data['Day']==day) & (data['Mnth']==month)][columnname].min()\n",
    "                yrsumMIN.loc[n,'Max']=data[(data['Day']==day) & (data['Mnth']==month)][columnname].max()\n",
    "                n=n+1\n",
    "\n",
    "    fig, ax1 = plt.subplots()\n",
    "    ax1.plot([0,365],[0,0],'k:')\n",
    "\n",
    "    ax1.plot(yrsumMAX['Max'],'r-',label='MaxMax')\n",
    "    ax1.plot(yrsumMAX['Median'],'k-',label='MedianMax',alpha=0.7)\n",
    "    ax1.plot(yrsumMAX['Min'],'r-',label='MinMax',alpha=0.2)\n",
    "\n",
    "    ax1.plot(yrsumMIN['Max'],'b-',label='MaxMin',alpha=0.2)\n",
    "    ax1.plot(yrsumMIN['Median'],'k-',label='MedianMin',alpha=0.7)\n",
    "    ax1.plot(yrsumMIN['Min'],'b-',label='MinMin')\n",
    "\n",
    "\n",
    "    plt.legend(bbox_to_anchor=(1.02, 1), loc=2, borderaxespad=0.)\n",
    "    plt.title('Annual Temperature Variations at Gauge '+str(gauge))\n",
    "    ax1.set_ylabel('Temperature (C)')\n",
    "    xticklabels=['Jan','Feb','Mar','Apr','May','Jun','Jul','Aug','Sep','Oct','Nov','Dec']\n",
    "    ax1.set_xticks([15,45,74,105,135,166,196,227,258,288,319,349],minor=False)\n",
    "    ax1.set_xticks([0,31,59,90,120,151,181,212,243,273,304,334,365],minor=True)\n",
    "    ax1.set_xticklabels(xticklabels)\n",
    "    ax1.tick_params(axis='x',which='major',bottom=False,top=False,labelbottom=True)\n",
    "    ax1.tick_params(axis='x',which='minor',bottom=True,top=False,labelbottom=False,width=-.5,length=18)\n",
    "    plt.show()\n",
    "    return fig \n",
    "\n",
    "def TypicalTemp_selectyear(gauge,selectedyear,dataset='daymet'):\n",
    "    \"\"\"shows max and min temps for a single year over historic spread \n",
    "    (admittedly a bit slow)\n",
    "    Dependent on loadforcing(gauge,dataset)\"\"\"\n",
    "\n",
    "    data=loadforcing(gauge,dataset)\n",
    "    data=data.replace(-999.0,np.nan)\n",
    "\n",
    "    columnname='tmax(C)'\n",
    "    yrsumMAX= pd.DataFrame(columns=['Month','Day','Median','Min','Max'])\n",
    "    n=0\n",
    "    for month in range(1,13,1):\n",
    "        if month in [9,4,6,11]: #30 \n",
    "            for day in range(1,31):\n",
    "                yrsumMAX.loc[n,'Month']=month\n",
    "                yrsumMAX.loc[n,'Day']=day\n",
    "                yrsumMAX.loc[n,'Median']=data[(data['Day']==day) & (data['Mnth']==month)][columnname].median()\n",
    "                yrsumMAX.loc[n,'Min']=data[(data['Day']==day) & (data['Mnth']==month)][columnname].min()\n",
    "                yrsumMAX.loc[n,'Max']=data[(data['Day']==day) & (data['Mnth']==month)][columnname].max()\n",
    "                n=n+1\n",
    "        if month in [1,3,5,7,8,10,12]: #31\n",
    "            for day in range(1,32):\n",
    "                yrsumMAX.loc[n,'Month']=month\n",
    "                yrsumMAX.loc[n,'Day']=day\n",
    "                yrsumMAX.loc[n,'Median']=data[(data['Day']==day) & (data['Mnth']==month)][columnname].median()\n",
    "                yrsumMAX.loc[n,'Min']=data[(data['Day']==day) & (data['Mnth']==month)][columnname].min()\n",
    "                yrsumMAX.loc[n,'Max']=data[(data['Day']==day) & (data['Mnth']==month)][columnname].max()\n",
    "                n=n+1\n",
    "        if month == 2: #stupid february\n",
    "            for day in range(1,29):\n",
    "                yrsumMAX.loc[n,'Month']=month\n",
    "                yrsumMAX.loc[n,'Day']=day\n",
    "                yrsumMAX.loc[n,'Median']=data[(data['Day']==day) & (data['Mnth']==month)][columnname].median()\n",
    "                yrsumMAX.loc[n,'Min']=data[(data['Day']==day) & (data['Mnth']==month)][columnname].min()\n",
    "                yrsumMAX.loc[n,'Max']=data[(data['Day']==day) & (data['Mnth']==month)][columnname].max()\n",
    "                n=n+1\n",
    "\n",
    "    columnname='tmin(C)'\n",
    "    yrsumMIN= pd.DataFrame(columns=['Month','Day','Median','Min','Max'])\n",
    "    n=0\n",
    "    for month in range(1,13,1):\n",
    "        if month in [9,4,6,11]: #30 \n",
    "            for day in range(1,31):\n",
    "                yrsumMIN.loc[n,'Month']=month\n",
    "                yrsumMIN.loc[n,'Day']=day\n",
    "                yrsumMIN.loc[n,'Median']=data[(data['Day']==day) & (data['Mnth']==month)][columnname].median()\n",
    "                yrsumMIN.loc[n,'Min']=data[(data['Day']==day) & (data['Mnth']==month)][columnname].min()\n",
    "                yrsumMIN.loc[n,'Max']=data[(data['Day']==day) & (data['Mnth']==month)][columnname].max()\n",
    "                n=n+1\n",
    "        if month in [1,3,5,7,8,10,12]: #31\n",
    "            for day in range(1,32):\n",
    "                yrsumMIN.loc[n,'Month']=month\n",
    "                yrsumMIN.loc[n,'Day']=day\n",
    "                yrsumMIN.loc[n,'Median']=data[(data['Day']==day) & (data['Mnth']==month)][columnname].median()\n",
    "                yrsumMIN.loc[n,'Min']=data[(data['Day']==day) & (data['Mnth']==month)][columnname].min()\n",
    "                yrsumMIN.loc[n,'Max']=data[(data['Day']==day) & (data['Mnth']==month)][columnname].max()\n",
    "                n=n+1\n",
    "        if month == 2: #stupid february\n",
    "            for day in range(1,29):\n",
    "                yrsumMIN.loc[n,'Month']=month\n",
    "                yrsumMIN.loc[n,'Day']=day\n",
    "                yrsumMIN.loc[n,'Median']=data[(data['Day']==day) & (data['Mnth']==month)][columnname].median()\n",
    "                yrsumMIN.loc[n,'Min']=data[(data['Day']==day) & (data['Mnth']==month)][columnname].min()\n",
    "                yrsumMIN.loc[n,'Max']=data[(data['Day']==day) & (data['Mnth']==month)][columnname].max()\n",
    "                n=n+1\n",
    "\n",
    "    fig, ax1 = plt.subplots()\n",
    "    ax1.plot([0,365],[0,0],'k:')\n",
    "    \n",
    "\n",
    "    ax1.plot(yrsumMAX['Max'],'r-',label='MaxMax',alpha=0.3)\n",
    "    ax1.plot(yrsumMAX['Median'],'k-',label='MedianMax',alpha=0.3)\n",
    "\n",
    "    ax1.plot(yrsumMIN['Median'],'k-',label='MedianMin',alpha=0.3)\n",
    "    ax1.plot(yrsumMIN['Min'],'b-',label='MinMin',alpha=0.3)\n",
    "\n",
    "\n",
    "    tempdata=data[data['Year'] == selectedyear]\n",
    "    ax1.plot(range(0,365),tempdata['tmin(C)'],'b-',label=str(selectedyear))\n",
    "    ax1.plot(range(0,365),tempdata['tmax(C)'],'r-',label=str(selectedyear))\n",
    "\n",
    "    plt.legend(bbox_to_anchor=(1.02, 1), loc=2, borderaxespad=0.)\n",
    "    plt.title('Annual Temperature Variations at Gauge '+str(gauge))\n",
    "    ax1.set_ylabel('Temperature (C)')\n",
    "    xticklabels=['Jan','Feb','Mar','Apr','May','Jun','Jul','Aug','Sep','Oct','Nov','Dec']\n",
    "    ax1.set_xticks([15,45,74,105,135,166,196,227,258,288,319,349],minor=False)\n",
    "    ax1.set_xticks([0,31,59,90,120,151,181,212,243,273,304,334,365],minor=True)\n",
    "    ax1.set_xticklabels(xticklabels)\n",
    "    ax1.tick_params(axis='x',which='major',bottom=False,top=False,labelbottom=True)\n",
    "    ax1.tick_params(axis='x',which='minor',bottom=True,top=False,labelbottom=False,width=-.5,length=18)\n",
    "    plt.show()\n",
    "    return fig"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Selected Gauges by Attributes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gaugefilter(subset,column,values):\n",
    "    \"\"\"Selects gauges that are within a range of values for a field in one of the attribute sets\n",
    "    subset options: \n",
    "      'name','geol','clim','hydro','soil','topo','vege'\n",
    "      'OtherAnalysis','fdc_info' \n",
    "    column is name of any numeric field in said subset\n",
    "    values of form [min,max]\n",
    "    dependent on returnattributeset(subset)\"\"\"\n",
    "    \n",
    "    #loading attributes/signatures \n",
    "    folder=home+'camels_attributes_v2.0/'; \n",
    "\n",
    "    df=returnattributeset(subset)\n",
    "    \n",
    "    filtered=df[(min(values)<df[column]) & (df[column]<max(values))]\n",
    "\n",
    "    acceptable=set(filtered.iloc[:,0])\n",
    "    return acceptable\n",
    "\n",
    "def plotsquare(xrange,yrange,boxtype='k:',label=[]):\n",
    "    \"\"\"Adds square of x/y range onto other plot\"\"\"\n",
    "    x=xrange[0],xrange[0],xrange[1],xrange[1],xrange[0]\n",
    "    y=yrange[0],yrange[1],yrange[1],yrange[0],yrange[0]\n",
    "    plt.plot(x,y,boxtype,label=label,alpha=0.8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Things other people made that are useful "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib\n",
    "from mpl_toolkits.axes_grid1 import AxesGrid\n",
    "\n",
    "def shiftedColorMap(cmap, start=0, midpoint=0.5, stop=1.0, name='shiftedcmap'):\n",
    "    '''\n",
    "    Function to offset the \"center\" of a colormap. Useful for\n",
    "    data with a negative min and positive max and you want the\n",
    "    middle of the colormap's dynamic range to be at zero.\n",
    "\n",
    "    Input\n",
    "    -----\n",
    "      cmap : The matplotlib colormap to be altered\n",
    "      start : Offset from lowest point in the colormap's range.\n",
    "          Defaults to 0.0 (no lower offset). Should be between\n",
    "          0.0 and `midpoint`.\n",
    "      midpoint : The new center of the colormap. Defaults to \n",
    "          0.5 (no shift). Should be between 0.0 and 1.0. In\n",
    "          general, this should be  1 - vmax / (vmax + abs(vmin))\n",
    "          For example if your data range from -15.0 to +5.0 and\n",
    "          you want the center of the colormap at 0.0, `midpoint`\n",
    "          should be set to  1 - 5/(5 + 15)) or 0.75\n",
    "      stop : Offset from highest point in the colormap's range.\n",
    "          Defaults to 1.0 (no upper offset). Should be between\n",
    "          `midpoint` and 1.0.\n",
    "    Thank you to Paul H on stackoverflow\n",
    "    See https://stackoverflow.com/questions/7404116/defining-the-midpoint-of-a-colormap-in-matplotlib \n",
    "    '''\n",
    "    cdict = {\n",
    "        'red': [],\n",
    "        'green': [],\n",
    "        'blue': [],\n",
    "        'alpha': []\n",
    "    }\n",
    "\n",
    "    # regular index to compute the colors\n",
    "    reg_index = np.linspace(start, stop, 257)\n",
    "\n",
    "    # shifted index to match the data\n",
    "    shift_index = np.hstack([\n",
    "        np.linspace(0.0, midpoint, 128, endpoint=False), \n",
    "        np.linspace(midpoint, 1.0, 129, endpoint=True)\n",
    "    ])\n",
    "\n",
    "    for ri, si in zip(reg_index, shift_index):\n",
    "        r, g, b, a = cmap(ri)\n",
    "\n",
    "        cdict['red'].append((si, r, r))\n",
    "        cdict['green'].append((si, g, g))\n",
    "        cdict['blue'].append((si, b, b))\n",
    "        cdict['alpha'].append((si, a, a))\n",
    "\n",
    "    newcmap = matplotlib.colors.LinearSegmentedColormap(name, cdict)\n",
    "    plt.register_cmap(cmap=newcmap)\n",
    "\n",
    "    return newcmap"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
